{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bb96cc-dc65-4a07-bfbf-0c481c92c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from estnltk import Text\n",
    "from estnltk.converters import json_to_text\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494c65c9-008a-4052-97d4-3f5424270313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wordlist(path):\n",
    "    \"\"\"Loeb faili, mis sisaldab stoppsõnu (üks sõna reas).\"\"\"\n",
    "    return Path(path).read_text(encoding='utf-8').splitlines()\n",
    "    \n",
    "stopid_s = load_wordlist('estonian-stopwords.txt')\n",
    "stopid_l = load_wordlist('estonian-stopwords-lemmas.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aea19a2-b725-4484-900a-4135be310e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(dirpath: str, gender_tag: str):\n",
    "    \"\"\"\n",
    "    Käib läbi kõik *.jsonid dirpathis ja tagastab kolmiku:\n",
    "      -  total_minutes (float)\n",
    "      - full_text (str)\n",
    "      - sections (sõnastikute loend)\n",
    "    Kus iga sõnastik sektsioonides sisaldab:\n",
    "      episode_id, section_index, gender, minutes, transcript\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    texts = []\n",
    "    total_seconds = 0.0\n",
    "\n",
    "    for p in Path(dirpath).glob('*.json'):\n",
    "        data = json.loads(p.read_text(encoding='utf-8'))\n",
    "        episode_id = p.stem\n",
    "        for idx, sec in enumerate(data.get('sections', [])):\n",
    "            turns = sec.get('turns')\n",
    "            if not turns:\n",
    "                continue\n",
    "            start, end = float(sec['start']), float(sec['end'])\n",
    "            total_seconds += (end - start)\n",
    "\n",
    "            # terve tekst\n",
    "            transcript = ' '.join(t['transcript'] for t in turns)\n",
    "            texts.append(transcript)\n",
    "\n",
    "            # metaandmed\n",
    "            records.append({\n",
    "                'episode_id':    episode_id,\n",
    "                'section_index': idx,\n",
    "                'gender':        gender_tag,\n",
    "                'minutes':       (end - start) / 60.0,\n",
    "                'transcript':    transcript\n",
    "            })\n",
    "\n",
    "    full_text = ' '.join(texts)\n",
    "    total_minutes = total_seconds / 60.0\n",
    "    return total_minutes, full_text, records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e26d12f-f2b1-4cd0-9c8c-ffb3e44d9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loendamine(kone):\n",
    "    \"\"\"\n",
    "    Salvestab kõik sõnad ja lemmad, mis ei ole kirjavahemärgid, loenditesse.\n",
    "    \"\"\"\n",
    "    \n",
    "    koik_sonad = []\n",
    "    koik_lemmad = []\n",
    "    \n",
    "    tekst = Text(kone).tag_layer('morph_analysis')\n",
    "    for sone in tekst.morph_analysis:\n",
    "        lemma = sone.lemma[0].lower()\n",
    "        soneliik = sone.partofspeech[0]\n",
    "                        \n",
    "        if soneliik != 'Z':\n",
    "            koik_lemmad.append(lemma)\n",
    "            koik_sonad.append(sone.text.lower())\n",
    "            \n",
    "    return koik_sonad, koik_lemmad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6c7096-84bf-4c2d-8c6f-4ab5d0fdaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeste kõnes kokku on 2590.5986666666695 minutit.\n",
      "Naiste kõnes kokku on 1982.9353333333322 minutit.\n",
      "\n",
      "Meeste kõnes kokku on 43.2 tundi\n",
      "Naiste kõnes kokku on 33.0 tundi\n"
     ]
    }
   ],
   "source": [
    "m_minutes, m_text,   men_sections   = process_folder('mehed',  'M')\n",
    "print('Meeste kõnes kokku on', m_minutes, 'minutit.')\n",
    "f_minutes, f_text,   women_sections = process_folder('naised','F')\n",
    "print('Naiste kõnes kokku on', f_minutes , 'minutit.')\n",
    "all_sections = men_sections + women_sections\n",
    "\n",
    "print()\n",
    "print('Meeste kõnes kokku on', round(m_minutes/60, 1), 'tundi')\n",
    "print('Naiste kõnes kokku on', round(f_minutes/60, 1), 'tundi')\n",
    "\n",
    "all_words_M, all_lemmas_M = loendamine(m_text)\n",
    "all_words_F, all_lemmas_F = loendamine(f_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70d763c7-db13-4a56-b237-bcd208e940c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350146\n",
      "287323\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words_M))\n",
    "print(len(all_words_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69bf68c7-eedd-4e65-a93e-d733d49b3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ttr(tokens):\n",
    "    \"\"\"\n",
    "      tokens: loend str - kõik tokenid (sõnad või lemmad)\n",
    "    tagastab type- token ratio\n",
    "    \"\"\"\n",
    "    n = len(tokens)\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    types = len(set(tokens))\n",
    "    return types / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc2e9ea-f6fd-4ffb-9e92-d571af0af25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Type–Token Ratio (lemmad) ===\n",
      "  Men:   0.0573\n",
      "  Women: 0.0467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TTR\n",
    "ttr_lemmas_M = compute_ttr(all_lemmas_M)\n",
    "ttr_lemmas_F = compute_ttr(all_lemmas_F)\n",
    "\n",
    "print(\"=== Type–Token Ratio (lemmad) ===\")\n",
    "print(f\"  Men:   {ttr_lemmas_M:.4f}\")\n",
    "print(f\"  Women: {ttr_lemmas_F:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ba20ab-861a-4c35-b910-72ab4cfff795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meeste kõnes kokku on 0.4 tundi\n",
      "Naiste kõnes kokku on 0.4 tundi\n",
      "=== Type–Token Ratio (lemmad) ===\n",
      "  Men:   0.2612\n",
      "  Women: 0.1906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_valitud_minutes, m_valitud_text,   men_valitud_sections   = process_folder('mehed_kinnisvara',  'M')\n",
    "f_valitud_minutes, f_valitud_text,   women_valitud_sections = process_folder('naised_kinnisvara','F')\n",
    "\n",
    "\n",
    "print()\n",
    "print('Meeste kõnes kokku on', round(m_valitud_minutes/60, 1), 'tundi')\n",
    "print('Naiste kõnes kokku on', round(f_valitud_minutes/60, 1), 'tundi')\n",
    "\n",
    "all_words_M_valitud, all_lemmas_M_valitud = loendamine(m_valitud_text)\n",
    "all_words_F_valitud, all_lemmas_F_valitud = loendamine(f_valitud_text)\n",
    "\n",
    "# TTR\n",
    "ttr_lemmas_M_valitud = compute_ttr(all_lemmas_M_valitud)\n",
    "ttr_lemmas_F_valitud = compute_ttr(all_lemmas_F_valitud)\n",
    "\n",
    "print(\"=== Type–Token Ratio (lemmad) ===\")\n",
    "print(f\"  Men:   {ttr_lemmas_M_valitud:.4f}\")\n",
    "print(f\"  Women: {ttr_lemmas_F_valitud:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c519fba0-07f1-44f8-88b4-c00dcdba0bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meeste kõnes kokku on 0.8 tundi\n",
      "Naiste kõnes kokku on 0.7 tundi\n",
      "=== Type–Token Ratio (lemmad) ===\n",
      "  Men:   0.1676\n",
      "  Women: 0.1620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m_valitud_minutes, m_valitud_text,   men_valitud_sections   = process_folder('mehed_esoteric',  'M')\n",
    "f_valitud_minutes, f_valitud_text,   women_valitud_sections = process_folder('naised_esoterc','F')\n",
    "\n",
    "print()\n",
    "print('Meeste kõnes kokku on', round(m_valitud_minutes/60, 1), 'tundi')\n",
    "print('Naiste kõnes kokku on', round(f_valitud_minutes/60, 1), 'tundi')\n",
    "\n",
    "all_words_M_valitud, all_lemmas_M_valitud = loendamine(m_valitud_text)\n",
    "all_words_F_valitud, all_lemmas_F_valitud = loendamine(f_valitud_text)\n",
    "\n",
    "# TTR\n",
    "ttr_lemmas_M_valitud = compute_ttr(all_lemmas_M_valitud)\n",
    "ttr_lemmas_F_valitud = compute_ttr(all_lemmas_F_valitud)\n",
    "\n",
    "print(\"=== Type–Token Ratio (lemmad) ===\")\n",
    "print(f\"  Men:   {ttr_lemmas_M_valitud:.4f}\")\n",
    "print(f\"  Women: {ttr_lemmas_F_valitud:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9604f532-fc9a-4ad9-9a4a-c6522791c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lemma_length(tokens):\n",
    "    \n",
    "    n = len(tokens)\n",
    "    average_len = sum(len(word) for word in tokens) / n\n",
    "    \n",
    "    return average_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1401fa0b-f747-40c9-9151-6438c249cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Keskmine pikkus (lemmad) ===\n",
      "  Men:   4.8046\n",
      "  Women: 4.9251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len_lemmas_M = compute_lemma_length(all_lemmas_M)\n",
    "len_lemmas_F = compute_lemma_length(all_lemmas_F)\n",
    "\n",
    "print(\"=== Keskmine pikkus (lemmad) ===\")\n",
    "print(f\"  Men:   {len_lemmas_M:.4f}\")\n",
    "print(f\"  Women: {len_lemmas_F:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210e8a4-402a-4add-97b2-bee45b6426c3",
   "metadata": {},
   "source": [
    "Sagedusloendid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e25913f-3b59-4b3d-b47e-410cb7fd027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_list(lemmas, stop_words):\n",
    "    \"\"\"\n",
    "    Loeb leemade sagedusloendi.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    freq_counter = Counter()\n",
    "    for lemma in lemmas:\n",
    "        if lemma not in stop_words:\n",
    "            freq_counter[lemma] += 1\n",
    "\n",
    "    return freq_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1721e6-624a-430b-91f8-6b0bfd707ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_fails(failinimi, loend):\n",
    "    \"\"\"\n",
    "    Salvestab lemmade sagedusloendi faili.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(failinimi, 'w', encoding='utf-8', newline='') as out_f:\n",
    "        writer = csv.writer(out_f, delimiter=';')\n",
    "        writer.writerow(['lemma', 'raw_count', 'freq_per_1000_lemmas'])\n",
    "        for lemma, cnt in loend.most_common():\n",
    "            freq_per_1000_lemmas = (cnt / len(loend)) * 1000\n",
    "            writer.writerow([lemma, cnt, f\"{freq_per_1000_lemmas:.3f}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "684a9ee2-a27c-4381-ac81-80fb4995655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out_M = 'n_grammid/lemmade_sagedus_by_min_M.csv'\n",
    "filename_out_F = 'n_grammid/lemmade_sagedus_by_min_F.csv'\n",
    "\n",
    "freq_fails(filename_out_M, freq_list(all_lemmas_M, stopid_l))\n",
    "freq_fails(filename_out_F, freq_list(all_lemmas_F, stopid_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85343f08-d095-4221-99ff-a4a9a66453c6",
   "metadata": {},
   "source": [
    "Bigrammid ja trigrammid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91b80e3c-37fd-4fe0-8bde-cc2f8a349a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_and_tri_grams(lemmas, stop_lemmas, words, stop_words):\n",
    "    \"\"\"\n",
    "    Loendab lemmasõnade ja algsõnade bigramme ja trigramme \n",
    "    lihtsustatud stoppsõnade filtreerimise reeglitega.\n",
    "    \n",
    "    Tagastab: (bigram_lem, trigram_lem, bigram_raw, trigram_raw)\n",
    "    \"\"\"\n",
    "    def count_ngrams(tokens, stop_set):\n",
    "        tokens_lower = [t.lower() for t in tokens]\n",
    "        N = len(tokens_lower)\n",
    "        bigrams = Counter()\n",
    "        trigrams = Counter()\n",
    "        # bigrammid: loendatakse, kui teine element ei ole stoppsõnades ja mõlemad elemedid on erinevad\n",
    "        for i in range(N - 1):\n",
    "            w1, w2 = tokens_lower[i], tokens_lower[i+1]\n",
    "            if w1 != w2 and w2 not in stop_set:\n",
    "                bigrams[(w1, w2)] += 1\n",
    "        # trigrammid: loendatakse, kui kõik kolm on erinevad ja esimene ning kolmas elemendid ei ole stoppsõnades.\n",
    "        for i in range(N - 2):\n",
    "            w1, w2, w3 = tokens_lower[i], tokens_lower[i+1], tokens_lower[i+2]\n",
    "            if len({w1, w2, w3}) == 3 and w1 not in stop_set and w3 not in stop_set:\n",
    "                trigrams[(w1, w2, w3)] += 1\n",
    "        return bigrams, trigrams\n",
    "\n",
    "    stop_lemmas_set = set(stop_lemmas)\n",
    "    stop_words_set  = set(stop_words)\n",
    "\n",
    "    # lemmade ja algsõnade kohta n-grammide loendamine\n",
    "    bigram_lem, trigram_lem = count_ngrams(lemmas, stop_lemmas_set)\n",
    "    bigram_raw, trigram_raw = count_ngrams(words,  stop_words_set)\n",
    "\n",
    "    # top 10\n",
    "    def print_top(cnt: Counter, title: str):\n",
    "        print(f\"Top 10 {title}:\")\n",
    "        for ngram, freq in cnt.most_common(10):\n",
    "            print(ngram, freq)\n",
    "        print()\n",
    "\n",
    "    print_top(bigram_lem,   \"bigrams (lemmas)\")\n",
    "    print_top(trigram_lem,  \"trigrams (lemmas)\")\n",
    "    print_top(bigram_raw,   \"bigrams (raw forms)\")\n",
    "    print_top(trigram_raw,  \"trigrams (raw forms)\")\n",
    "\n",
    "    return bigram_lem, trigram_lem, bigram_raw, trigram_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e65092e7-d8b1-4b71-a8c5-e5b18ea15633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mehed:\n",
      "\n",
      "Top 10 bigrams (lemmas):\n",
      "('ei', 'teadma') 854\n",
      "('mina', 'arvama') 656\n",
      "('see', 'mõte') 531\n",
      "('mina', 'ütlema') 346\n",
      "('see', 'asi') 302\n",
      "('saama', 'aru') 298\n",
      "('mina', 'tahtma') 289\n",
      "('mina', 'arust') 273\n",
      "('kogu', 'aeg') 236\n",
      "('mina', 'rääkima') 182\n",
      "\n",
      "Top 10 trigrams (lemmas):\n",
      "('eesti', 'puue', 'inimene') 28\n",
      "('puue', 'inimene', 'koda') 27\n",
      "('mees', 'ei', 'nutma') 20\n",
      "('no', 'see', 'mõte') 17\n",
      "('teadma', 'mis', 'asi') 13\n",
      "('no', 'mina', 'ütlema') 12\n",
      "('jutt', 'roheline', 'stuudio') 10\n",
      "('ütlema', 'et', 'kuulma') 10\n",
      "('tõde', 'ja', 'õigus') 9\n",
      "('no', 'mina', 'arvama') 9\n",
      "\n",
      "Top 10 bigrams (raw forms):\n",
      "('ei', 'tea') 793\n",
      "('ma', 'arvan') 597\n",
      "('selles', 'mõttes') 467\n",
      "('minu', 'arust') 272\n",
      "('kogu', 'aeg') 234\n",
      "('ma', 'ütlen') 145\n",
      "('see', 'ongi') 127\n",
      "('väga', 'hea') 122\n",
      "('ma', 'tean') 122\n",
      "('saan', 'aru') 118\n",
      "\n",
      "Top 10 trigrams (raw forms):\n",
      "('eesti', 'puuetega', 'inimeste') 22\n",
      "('mehed', 'ei', 'nuta') 18\n",
      "('no', 'selles', 'mõttes') 17\n",
      "('jutud', 'rohelises', 'stuudios') 10\n",
      "('no', 'ma', 'arvan') 9\n",
      "('puuetega', 'inimeste', 'kojas') 8\n",
      "('puuetega', 'inimeste', 'koja') 8\n",
      "('no', 'ma', 'ütlen') 8\n",
      "('konsultant', 'ja', 'koolitaja') 6\n",
      "('tegelikult', 'ma', 'arvan') 6\n",
      "\n",
      "\n",
      "Naised:\n",
      "\n",
      "Top 10 bigrams (lemmas):\n",
      "('ei', 'teadma') 445\n",
      "('mina', 'arvama') 374\n",
      "('see', 'mõte') 300\n",
      "('mina', 'tahtma') 291\n",
      "('mina', 'ütlema') 226\n",
      "('olema', 'tegelikult') 226\n",
      "('mina', 'rääkima') 211\n",
      "('see', 'inimene') 207\n",
      "('olema', 'hästi') 201\n",
      "('olema', 'vaja') 177\n",
      "\n",
      "Top 10 trigrams (lemmas):\n",
      "('tartu', 'noorsootöö', 'keskus') 19\n",
      "('mees', 'ja', 'naine') 13\n",
      "('noor', 'vaimne', 'tervis') 11\n",
      "('ütlema', 'et', 'kuulma') 10\n",
      "('hästi', 'palju', 'erinev') 9\n",
      "('ema', 'ja', 'isa') 8\n",
      "('teinekord', 'ikka', 'jälle') 8\n",
      "('no', 'mina', 'arvama') 8\n",
      "('no', 'mina', 'ütlema') 8\n",
      "('puudutama', 'mina', 'saade') 7\n",
      "\n",
      "Top 10 bigrams (raw forms):\n",
      "('ei', 'tea') 414\n",
      "('ma', 'arvan') 337\n",
      "('selles', 'mõttes') 274\n",
      "('et', 'tegelikult') 172\n",
      "('kogu', 'aeg') 157\n",
      "('on', 'tegelikult') 156\n",
      "('on', 'hästi') 144\n",
      "('ma', 'tahan') 136\n",
      "('on', 'vaja') 126\n",
      "('me', 'räägime') 116\n",
      "\n",
      "Top 10 trigrams (raw forms):\n",
      "('tartu', 'noorsootöö', 'keskuse') 10\n",
      "('vaatasite', 'vaadake', 'teinekord') 9\n",
      "('teinekord', 'ikka', 'jälle') 8\n",
      "('no', 'ma', 'arvan') 8\n",
      "('hästi', 'palju', 'erinevaid') 7\n",
      "('head', 'uut', 'aastat') 7\n",
      "('no', 'selles', 'mõttes') 6\n",
      "('aru', 'et', 'okei') 6\n",
      "('varem', 'või', 'hiljem') 6\n",
      "('hästi', 'kuulmiseni', 'nägemiseni') 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Mehed:')\n",
    "print()\n",
    "bigrammid_lem_M, trigrammid_lem_M, bigrammid_raw_M, trigrammid_raw_M = bi_and_tri_grams(all_lemmas_M, stopid_l, all_words_M, stopid_s)\n",
    "print()\n",
    "print('Naised:')\n",
    "print()\n",
    "bigrammid_lem_F, trigrammid_lem_F, bigrammid_raw_F, trigrammid_raw_F = bi_and_tri_grams(all_lemmas_F, stopid_l, all_words_F, stopid_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01b21829-8cc4-4a00-9ea6-4a1957cd03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ngrams(counter, out_path, sep: str = ';', precision: int = 4):\n",
    "    \"\"\"\n",
    "   Salvestab n-grammid loendurist CSV-formaadis veergudega:\n",
    "      ngramm, count, freq_per_1000_n-gramms\n",
    "    \"\"\"\n",
    "    total_ngrams = sum(counter.values())\n",
    "    \n",
    "    factor = 1000.0 / total_ngrams if total_ngrams else 0.0\n",
    "    \n",
    "    p = Path(out_path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with p.open('w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter=sep)\n",
    "        writer.writerow(['ngram', 'count', 'freq_per_1000_n-gramms'])\n",
    "        fmt = f'{{:.{precision}f}}'\n",
    "        for ngram, cnt in counter.most_common():\n",
    "            # Kui ngram on tupel, siis liimi, muidu valatakse str-iks\n",
    "            text = ' '.join(ngram) if isinstance(ngram, (list, tuple)) else str(ngram)\n",
    "            writer.writerow([text, cnt, fmt.format(cnt * factor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3878e73-3c56-4469-ac85-1c3438b5071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_ja_tri_failid(bigram_lem_fpath,   trigram_lem_fpath,\n",
    "                    bigram_raw_fpath,   trigram_raw_fpath,\n",
    "                    bigram_counter_lem, trigram_counter_lem,\n",
    "                    bigram_counter_raw, trigram_counter_raw):\n",
    "    \"\"\"\n",
    "    Salvestab neli CSV-d: lemmade bigrammid/trigrammid ja algsõnade bigrammid/trigrammid.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        bigram_lem_fpath:   bigram_counter_lem,\n",
    "        trigram_lem_fpath:  trigram_counter_lem,\n",
    "        bigram_raw_fpath:   bigram_counter_raw,\n",
    "        trigram_raw_fpath:  trigram_counter_raw,\n",
    "    }\n",
    "    for path, counter in mapping.items():\n",
    "        save_ngrams(counter, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4dfaec9-1d7c-4d7f-8e89-d8d8d5c3c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_bigrams_lemma_M = 'n_grammid/bigrams_lemma_per_1000_ngramms_mehed.csv'\n",
    "filename_trigrams_lemma_M = 'n_grammid/trigrams_lemma_per_1000_ngramms_mehed.csv'\n",
    "filename_bigrams_raw_M = 'n_grammid/bigrams_raw_per_1000_ngramms_mehed.csv'\n",
    "filename_trigrams_raw_M = 'n_grammid/trigrams_raw_per_1000_ngramms_mehed.csv'\n",
    "\n",
    "filename_bigrams_lemma_F = 'n_grammid/bigrams_lemma_per_1000_ngramms_naised.csv'\n",
    "filename_trigrams_lemma_F = 'n_grammid/trigrams_lemma_per_1000_ngramms_naised.csv'\n",
    "filename_bigrams_raw_F = 'n_grammid/bigrams_raw_per_1000_ngramms_naised.csv'\n",
    "filename_trigrams_raw_F = 'n_grammid/trigrams_raw_per_1000_ngramms_naised.csv'\n",
    "\n",
    "bi_ja_tri_failid(filename_bigrams_lemma_M, filename_trigrams_lemma_M, filename_bigrams_raw_M, filename_trigrams_raw_M, \n",
    "                    bigrammid_lem_M, trigrammid_lem_M, bigrammid_raw_M, trigrammid_raw_M)\n",
    "bi_ja_tri_failid(filename_bigrams_lemma_F, filename_trigrams_lemma_F, filename_bigrams_raw_F, filename_trigrams_raw_F, \n",
    "                    bigrammid_lem_F, trigrammid_lem_F, bigrammid_raw_F, trigrammid_raw_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976984a3-20f1-4763-9a1d-39b2dadbd4b0",
   "metadata": {},
   "source": [
    "Sõnaliigid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e68c129-58fb-4f34-b352-43703e9dc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos(text_str: str,\n",
    "              skip_lemmas: set[str],\n",
    "              stop_lemmas: set[str]\n",
    "             ) -> dict[str, Counter]:\n",
    "    \"\"\"\n",
    "    Loendab tekstis lemmade esinemissagedust sõnaliikide kaupa.\n",
    "\n",
    "    Kui eelmise token'i lemmavorm kattub käesoleva token'i lemmaga,\n",
    "    siis käesolevat token'it ei arvestata loendurites.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text_str : str\n",
    "        Analüüsitav algtekst.\n",
    "    skip_lemmas : set[str]\n",
    "        Lemmad (väiketähtedega), mida ignoreeritakse (nt sagedased sõnad).\n",
    "    stop_lemmas : set[str]\n",
    "        Abiverbide lemmad (nt 'olema', 'saama' jm), mille puhul loendame\n",
    "        abiverbide alla.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Counter]\n",
    "        Loendurid sõnaliikide kaupa.\n",
    "    \"\"\"\n",
    "    txt = Text(text_str)\n",
    "    txt.tag_layer('morph_analysis')\n",
    "\n",
    "    counters: dict[str, Counter] = {\n",
    "        'omadussõnad': Counter(),\n",
    "        'nimisõnad':   Counter(),\n",
    "        'adverbid':    Counter(),\n",
    "        'verbid':      Counter(),\n",
    "        'abiverbid':   Counter(),\n",
    "        'asesõnad':    Counter(),\n",
    "        'kaassõnad':   Counter(),\n",
    "    }\n",
    "\n",
    "    tag_map = {\n",
    "        'A': 'omadussõnad',\n",
    "        'S': 'nimisõnad',\n",
    "        'D': 'adverbid',\n",
    "        'P': 'asesõnad',\n",
    "        'K': 'kaassõnad',\n",
    "    }\n",
    "\n",
    "    prev_lemma: str | None = None        # lemmavorm eelmisest tokenist\n",
    "    for token in txt.morph_analysis:\n",
    "        lemma = token.lemma[0].lower()\n",
    "        tag   = token.partofspeech[0]\n",
    "\n",
    "        # Jäta vahele, kui lemmaga tuleb alati vahele jätta\n",
    "        if lemma in skip_lemmas:\n",
    "            prev_lemma = lemma           # uuenda prev_lemma ja jätka\n",
    "            continue\n",
    "\n",
    "        # Jäta vahele, kui eelmise token'i lemmaga sama\n",
    "        if prev_lemma == lemma:\n",
    "            prev_lemma = lemma\n",
    "            continue\n",
    "\n",
    "        # Loenda verbid / abiverbid\n",
    "        if tag == 'V':\n",
    "            bucket = 'abiverbid' if lemma in stop_lemmas else 'verbid'\n",
    "            counters[bucket][lemma] += 1\n",
    "\n",
    "        # Loenda muud huvipakkuvad sõnaliigid\n",
    "        elif tag in tag_map:\n",
    "            counters[tag_map[tag]][lemma] += 1\n",
    "\n",
    "        # Uuenda eelmise lemmavormi meelespidamine\n",
    "        prev_lemma = lemma\n",
    "\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b70e7f8c-299b-4e79-a9e2-c939284e675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 15253 lines - pos_sections_csv/omadussõnad_by_section.csv\n",
      "Saved 58428 lines - pos_sections_csv/nimisõnad_by_section.csv\n",
      "Saved 34869 lines - pos_sections_csv/adverbid_by_section.csv\n",
      "Saved 25712 lines - pos_sections_csv/verbid_by_section.csv\n",
      "Saved 3402 lines - pos_sections_csv/abiverbid_by_section.csv\n",
      "Saved 8783 lines - pos_sections_csv/asesõnad_by_section.csv\n",
      "Saved 5379 lines - pos_sections_csv/kaassõnad_by_section.csv\n"
     ]
    }
   ],
   "source": [
    "## Lemmad, mis tähistavad eitust\n",
    "negation = ['ei', 'ära']\n",
    "\n",
    "# DataFrame\n",
    "records = []\n",
    "for sec in all_sections:\n",
    "    # Sageduste loendamine sõnaliikide kategooriate kaupa transkriptsiooni lõigu kohta\n",
    "    counts = count_pos(sec['transcript'], negation, stopid_l)\n",
    "    for pos, counter in counts.items():\n",
    "        for form, cnt in counter.items():\n",
    "            if sec['gender'] == 'M':\n",
    "                freq = (cnt / len(all_words_M)) * 1000 if len(all_words_M) > 0 else 0.0\n",
    "            else:\n",
    "                freq = (cnt / len(all_words_F)) * 1000 if len(all_words_F) > 0 else 0.0\n",
    "            records.append({\n",
    "                'episode_id': sec['episode_id'].split('_', 1)[0],    # episoodi id\n",
    "                'section_index': sec['section_index'],# lõigu järjekorranumber episoodis\n",
    "                'gender': sec['gender'],              # esineja sugu\n",
    "                'minutes': sec['minutes'],            # lõigu kestus minutites\n",
    "                'pos': pos,                           # sõnaliik (count_pos võti)\n",
    "                'feature': form,                      # sõna \n",
    "                'raw_count': cnt,                     # esinemiste arv tekstis\n",
    "                'freq_per_1000_tokens': freq               # 1000 sõnede normaliseeritud sagedus\n",
    "            })\n",
    "\n",
    "df_sections_pos = pd.DataFrame(records)\n",
    "\n",
    "# Salvestame iga POS-i jaoks eraldi CSV-faili\n",
    "os.makedirs('pos_sections_csv', exist_ok=True) #vaata GitHubis sõnaliigid kausta\n",
    "for pos in df_sections_pos['pos'].unique():\n",
    "    df_subset = df_sections_pos[df_sections_pos['pos'] == pos]\n",
    "    filename = f'pos_sections_csv/{pos}_by_section.csv'\n",
    "    df_subset.to_csv(filename, index=False)\n",
    "\n",
    "     # Teade salvestamise kohta\n",
    "    print(f\"Saved {len(df_subset)} lines - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58846e11-b1ac-4414-91bf-c3ebd83b4d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaassõnad_by_section.csv → pos_sections_csv/pos_sections_counter/kaassõnad_by_section.csv\n",
      "omadussõnad_by_section.csv → pos_sections_csv/pos_sections_counter/omadussõnad_by_section.csv\n",
      "abiverbid_by_section.csv → pos_sections_csv/pos_sections_counter/abiverbid_by_section.csv\n",
      "verbid_by_section.csv → pos_sections_csv/pos_sections_counter/verbid_by_section.csv\n",
      "adverbid_by_section.csv → pos_sections_csv/pos_sections_counter/adverbid_by_section.csv\n",
      "nimisõnad_by_section.csv → pos_sections_csv/pos_sections_counter/nimisõnad_by_section.csv\n",
      "asesõnad_by_section.csv → pos_sections_csv/pos_sections_counter/asesõnad_by_section.csv\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'pos_sections_csv'  #vaata GitHubis sõnaliigid kausta\n",
    "output_dir = 'pos_sections_csv/pos_sections_counter'\n",
    "# Loome väljundkausta, kui seda veel pole\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Töötleme iga CSV-faili sisendkaustas\n",
    "\n",
    "for filepath in glob.glob(os.path.join(input_dir, '*.csv')):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    grouped = (\n",
    "        df\n",
    "        .drop(columns=['feature'])\n",
    "        .groupby(['episode_id', 'section_index', 'gender', 'minutes', 'pos'], as_index=False)\n",
    "        .agg({\n",
    "            'raw_count': 'sum',          \n",
    "    )\n",
    "        \n",
    "    def calc_freq(row):\n",
    "        cnt = row['raw_count']\n",
    "        if row['gender'] == 'M':\n",
    "            return (cnt / all_words_M) * 1000 if all_words_M > 0 else 0.0\n",
    "        else:\n",
    "            return (cnt / all_words_F) * 1000 if all_words_F > 0 else 0.0\n",
    "\n",
    "    grouped['freq_per_1000_tokens'] = grouped.apply(calc_freq, axis=1)\n",
    "            \n",
    "    filename = os.path.basename(filepath)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    grouped.to_csv(output_path, index=False)\n",
    "    \n",
    "     # Teade salvestamise kohta\n",
    "    print(f'{filename} → {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a165f250-5195-4211-a98b-06f00e5cd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "eituse_partiklid = ['ei', 'ära']\n",
    "es_ja_te_pronoomenid = ['mina', 'sina']\n",
    "tingiv_koneviis = ['ks', 'ksin', 'ksid', 'ksime', 'ksite', 'taks', 'nuksin', 'nuksid', 'nuks', 'nuksime', 'nuksite', 'tuks']\n",
    "umbisikuline = ['ti', 'takse', 'ta', 'tud', 'taks', 'tuks']\n",
    "kaskiv_koneviis = ['o', 'ge', 'gem']\n",
    "kp_markerid = ['arvan', 'usun', 'kardan', 'tundub', 'paistab', 'näib', 'loodan', 'ütleme']\n",
    "verbid_partiklitena = ['ootama', 'vaatama', 'kuulama', 'kuulma']\n",
    "\n",
    "intensiivistajad_loendist = []\n",
    "with open('intensiivistajad.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        intensiivistajad_loendist.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23ecef09-7afc-482b-82a7-4f07299531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initsialiseerime tühjad loendid erinevate tunnuste jaoks\n",
    "eitused = []                               # eitused (näiteks 'ei' + verb)\n",
    "esimese_ja_teise_isik = []                # 1. ja 2. isiku pronoomenid\n",
    "intensiivistajad_omadussonadega = []      # intensiivistajad + omadussõnad\n",
    "intensiivistajad_verbidega = []           # intensiivistajad + verbid\n",
    "intensiivistajad_adverbidega = []         # intensiivistajad + adverbid\n",
    "tingiv_koneviis_loend = []                # tingiv kõneviis\n",
    "umbisikuline_loend = []                   # umbisikuline vorm\n",
    "kaskiv_koneviis_loend = []                # käsiv kõneviis\n",
    "kp_markerid_loend = []                    # kõnepartiklid markeritena\n",
    "verbid_partiklitena_loend = []           # verbid, mis on partiklitena\n",
    "partiklid = []                            # kõik leitud partiklid\n",
    "intensiivistajad = []\n",
    "deminutiivid = []\n",
    "\n",
    "for sec in all_sections:\n",
    "    plok = sec['transcript']\n",
    "\n",
    "    plok_nltk = Text(plok).tag_layer('morph_analysis')\n",
    "    for lause in plok_nltk.sentences:      \n",
    "        for i, sone in enumerate(lause):\n",
    "            episodi_id = sec['episode_id'].split('_', 1)[0]\n",
    "            if sone.lemma[0].endswith('kene') and sone.lemma[0] not in ['kene', 'skene']:\n",
    "                deminutiivid.append({\n",
    "                    'episode_id': episodi_id,\n",
    "                    'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'],\n",
    "                    'minutes': sec['minutes'],\n",
    "                    'sõna': sone.lemma[0],\n",
    "                    'lause': \" \".join(tok.text for tok in lause)\n",
    "                })\n",
    "            # 1) Eitused: eituse partikkel + järgneb verb\n",
    "            if sone.lemma[0] in eituse_partiklid and i+1 < len(lause) and lause[i+1].partofspeech[0] == 'V':\n",
    "                eitused.append({\n",
    "                    'episode_id': episodi_id,\n",
    "                    'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'],\n",
    "                    'minutes': sec['minutes'],\n",
    "                    'eitus': sone.lemma[0],\n",
    "                    'verb': lause[i+1].lemma[0],\n",
    "                    'lause': \" \".join(tok.text for tok in lause)\n",
    "                })\n",
    "            # 2) 1. ja 2. isiku pronoomenid\n",
    "            if sone.lemma[0] in es_ja_te_pronoomenid:\n",
    "                esimese_ja_teise_isik.append({\n",
    "                    'episode_id': episodi_id,\n",
    "                    'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'],\n",
    "                    'minutes': sec['minutes'],\n",
    "                    'tunnus': sone.text.lower(),\n",
    "                    'lause': \" \".join(tok.text for tok in lause)\n",
    "                })\n",
    "            # 3) Intensiivistajad (järgneva sõna POS-i järgi)\n",
    "            if sone.lemma[0] in intensiivistajad_loendist and i+1 < len(lause):\n",
    "                järgnev_pos = lause[i+1].partofspeech[0]\n",
    "                if järgnev_pos in ['A', 'V', 'D']:\n",
    "                    intensiivistajad.append({\n",
    "                        'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                        'pos': järgnev_pos, 'tunnus': sone.lemma[0],\n",
    "                        'sona': lause[i+1].lemma[0], 'lause': \" \".join(tok.text for tok in lause)\n",
    "                    })\n",
    "                    # Omadussõnadega\n",
    "                    if järgnev_pos == 'A':\n",
    "                        intensiivistajad_omadussonadega.append({\n",
    "                            'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                            'pos': 'A', 'tunnus': sone.lemma[0],\n",
    "                            'sona': lause[i+1].lemma[0], 'lause': \" \".join(tok.text for tok in lause)\n",
    "                        })\n",
    "                    # Verbidega\n",
    "                    elif järgnev_pos == 'V':\n",
    "                        intensiivistajad_verbidega.append({\n",
    "                            'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                            'pos': 'V', 'tunnus': sone.lemma[0],\n",
    "                            'sona': lause[i+1].lemma[0], 'lause': \" \".join(tok.text for tok in lause)\n",
    "                        })\n",
    "                    # Adverbidega\n",
    "                    elif järgnev_pos == 'D':\n",
    "                        intensiivistajad_adverbidega.append({\n",
    "                            'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                            'pos': 'D', 'tunnus': sone.lemma[0],\n",
    "                            'sona': lause[i+1].lemma[0], 'lause': \" \".join(tok.text for tok in lause)\n",
    "                        })\n",
    "            # 4) Partiklid (I) ja sõna 'nagu', välistame tervituse 'tere'\n",
    "            if sone.partofspeech[0] == 'I' or sone.lemma[0] == 'nagu':\n",
    "                if sone.lemma[0] in ['tere', 'aitäh']:\n",
    "                    continue  # välista tavatervitus\n",
    "                # Kontrollime, et indeksid lauses on lubitud\n",
    "                if 0 <= i-2 < len(lause) and 0 <= i+2 < len(lause):\n",
    "                    # Lisa ainult siis, kui murranguline kontekst\n",
    "                    if lause[i-2].text != sone.text or lause[i+2].text != sone.text:\n",
    "                        partiklid.append({\n",
    "                            'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                            'tunnus': sone.lemma[0],\n",
    "                            'lause': \" \".join(tok.text for tok in lause)\n",
    "                        })\n",
    "            if sone.lemma[0] == 'eks' and lause[i+1].lemma[0] == 'olema':\n",
    "                partiklid.append({\n",
    "                    'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                    'tunnus': 'eks ole',\n",
    "                    'lause': \" \".join(tok.text for tok in lause)\n",
    "                })\n",
    "            if sone.lemma[0] == 'jumal':\n",
    "                partiklid.append({\n",
    "                    'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                    'tunnus': sone.lemma[0],\n",
    "                    'lause': \" \".join(tok.text for tok in lause)\n",
    "                })\n",
    "            # 5) Verbide eritunnused: kõnepartiklid, kõneviisid, vormid\n",
    "            if sone.partofspeech[0] == 'V':\n",
    "                # Kõnepartikli markerid\n",
    "                if sone.text in kp_markerid:\n",
    "                    kp_markerid_loend.append({\n",
    "                        'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                        'tunnus': sone.lemma[0], 'lause': \" \".join(tok.text for tok in lause)\n",
    "                    })\n",
    "                # Tingiv kõneviis\n",
    "                if sone.form[0] in tingiv_koneviis:\n",
    "                    tingiv_koneviis_loend.append({\n",
    "                        'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                        'verb': sone.text, 'lause': \" \".join(tok.text for tok in lause)\n",
    "                    })\n",
    "                # Umbisikuline vorm\n",
    "                elif sone.form[0] in umbisikuline:\n",
    "                    umbisikuline_loend.append({\n",
    "                        'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                        'verb': sone.text, 'lause': \" \".join(tok.text for tok in lause)\n",
    "                    })\n",
    "                # Käskiv kõneviis\n",
    "                elif sone.form[0] in kaskiv_koneviis and lause[i-1].text.lower() not in ['ei', 'et']:\n",
    "                    # Erinevus verb-partikkel vs tõeline käsuvorm\n",
    "                    if sone.lemma[0] in verbid_partiklitena:\n",
    "                        verbid_partiklitena_loend.append({\n",
    "                            'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                            'verb': sone.text, 'lause': \" \".join(tok.text for tok in lause)\n",
    "                        })\n",
    "                    else:\n",
    "                        kaskiv_koneviis_loend.append({\n",
    "                            'episode_id': episodi_id, 'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'], 'minutes': sec['minutes'],\n",
    "                            'verb': sone.text, 'lause': \" \".join(tok.text for tok in lause)\n",
    "                        })\n",
    "\n",
    "# Muudame loendid DataFrame'ideks ja salvestame CSV-failid kontrollimiseks\n",
    "df_eitused = pd.DataFrame(eitused)\n",
    "df_esimese_ja_teise_isik = pd.DataFrame(esimese_ja_teise_isik)\n",
    "df_intensiivistajad_omadussonadega = pd.DataFrame(intensiivistajad_omadussonadega)\n",
    "df_intensiivistajad_verbidega = pd.DataFrame(intensiivistajad_verbidega)\n",
    "df_intensiivistajad_adverbidega = pd.DataFrame(intensiivistajad_adverbidega)\n",
    "df_tingiv = pd.DataFrame(tingiv_koneviis_loend)\n",
    "df_umbisikuline = pd.DataFrame(umbisikuline_loend)\n",
    "df_kaskiv = pd.DataFrame(kaskiv_koneviis_loend)\n",
    "df_kp = pd.DataFrame(kp_markerid_loend)\n",
    "df_verbid_partiklitena = pd.DataFrame(verbid_partiklitena_loend)\n",
    "df_partiklid = pd.DataFrame(partiklid)\n",
    "df_intensiivistajad = pd.DataFrame(intensiivistajad)\n",
    "df_deminutiivid = pd.DataFrame(deminutiivid)\n",
    "\n",
    "# Salvestame iga tunnuse CSV-faili\n",
    "os.makedirs('tabelid_kontrollimiseks', exist_ok=True)\n",
    "df_eitused.to_csv('tabelid_kontrollimiseks/eitused.csv', index=False)\n",
    "df_esimese_ja_teise_isik.to_csv('tabelid_kontrollimiseks/esimese_ja_teise_isik.csv', index=False)\n",
    "df_intensiivistajad_omadussonadega.to_csv('tabelid_kontrollimiseks/intensiivistajad_omadussonadega.csv', index=False)\n",
    "df_intensiivistajad_verbidega.to_csv('tabelid_kontrollimiseks/intensiivistajad_verbidega.csv', index=False)\n",
    "df_intensiivistajad_adverbidega.to_csv('tabelid_kontrollimiseks/intensiivistajad_adverbidega.csv', index=False)\n",
    "df_tingiv.to_csv('tabelid_kontrollimiseks/tingiv.csv', index=False)\n",
    "df_umbisikuline.to_csv('tabelid_kontrollimiseks/umbisikuline.csv', index=False)\n",
    "df_kaskiv.to_csv('tabelid_kontrollimiseks/kaskiv.csv', index=False)\n",
    "df_kp.to_csv('tabelid_kontrollimiseks/kp_markerid.csv', index=False)\n",
    "df_verbid_partiklitena.to_csv('tabelid_kontrollimiseks/vaata_oota.csv', index=False)\n",
    "df_partiklid.to_csv('tabelid_kontrollimiseks/partiklid.csv', index=False)\n",
    "df_intensiivistajad.to_csv('tabelid_kontrollimiseks/intensiivistajad.csv', index=False)\n",
    "df_deminutiivid.to_csv('tabelid_kontrollimiseks/deminutiivid.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5622974c-4b07-4133-bd4b-abf105707f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tabelid_kontrollimiseks/vaata_oota.csv')\n",
    "\n",
    "\n",
    "particles = ['no', 'noh', 'nagu', 'aga', 'siis']\n",
    "particle_pat = r'(?:' + '|'.join(particles) + r')'  # (?:no|noh|nagu|aga|siis)\n",
    "\n",
    "def classify(row):\n",
    "    verb = re.escape(row['verb'])\n",
    "    text = row['lause']\n",
    "\n",
    "    # verbi rea alguses, millele järgneb koma\n",
    "    start_pattern = rf'(?i)^\\s*{verb}\\b\\s*,'\n",
    "    if re.match(start_pattern, text):\n",
    "        return 1\n",
    "\n",
    "    # või\n",
    "    any_pattern = (\n",
    "        rf'(?i)'                    \n",
    "        rf'\\b'                          # sõna piir\n",
    "        rf'(?:{particle_pat}\\s+)?'      # partikkel enne\n",
    "        rf'{verb}\\b'                    # verb\n",
    "        rf'(?:\\s+{particle_pat})?'      # partikkel pärast\n",
    "        rf'\\s*,'                        # tühikud (kui on), koma\n",
    "    )\n",
    "    return 1 if re.search(any_pattern, text) else 0\n",
    "\n",
    "df['mood_flag'] = df.apply(classify, axis=1)\n",
    "df.to_csv('tabelid_kontrollimiseks/verbid_partiklitena_kontrollimiseks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0059b-a8df-4c2a-94f0-dcba7a0cb9ce",
   "metadata": {},
   "source": [
    "Kui tabelid on kontrollitud!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a0d08ab-a427-423d-b979-2382df418989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tabelid_kontrollimiseks/verbid_partiklitena_kontrollitud_uus.csv\n"
     ]
    }
   ],
   "source": [
    "input_path  = \"tabelid_kontrollimiseks/verbid_partiklitena_kontrollitud.csv\"\n",
    "output_path = \"tabelid_kontrollimiseks/verbid_partiklitena_kontrollitud_uus.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path, sep=\";\")\n",
    "df[\"mood_flag\"] = pd.to_numeric(df[\"mood_flag\"], errors=\"coerce\")\n",
    "df_clean = df[df[\"mood_flag\"] != 0]\n",
    "df_clean.to_csv(output_path, sep=\";\", index=False)\n",
    "\n",
    "print(f\"Saved {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd5704ac-abb8-4f21-aa75-0a07cd83bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_section_counts(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    sep: str = ';',\n",
    "    group_cols: list = None\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"\n",
    "    Agregeerib sektsioonide loendused ja arvutab tunnusõnasageduse tunnis.\n",
    "\n",
    "    Parameetrid:\n",
    "    -------------\n",
    "    input_path : str\n",
    "        Sisend CSV-faili tee sektsioonide loendustega.\n",
    "    output_path : str\n",
    "        Väljundfaili tee, kuhu salvestatakse agregeeritud tulemused.\n",
    "    sep : str, valikuline\n",
    "        Veerude eraldaja CSV-failis (vaikimisi ';').\n",
    "    group_cols : list, valikuline\n",
    "        Veergude nimed, mille alusel grupeerida. Kui None, kasutatakse\n",
    "        ['episode_id', 'section_index', 'gender', 'minutes'].\n",
    "\n",
    "    Tagastab:\n",
    "    ----------\n",
    "    pd.DataFrame\n",
    "        DataFrame, mis sisaldab veerge grupiviisilise grupeerimise,\n",
    "        'absolut_freq' ja 'freq_per_hour'.\n",
    "    \"\"\"\n",
    "   \n",
    "    df = pd.read_csv(input_path, sep=sep)\n",
    "    \n",
    "   # Kui grupeerimisveerud pole antud, määrame vaikimisi\n",
    "    if group_cols is None:\n",
    "        group_cols = ['episode_id', 'section_index', 'gender', 'minutes']\n",
    "    \n",
    "\n",
    "    grouped = (\n",
    "        df\n",
    "        .groupby(group_cols, as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={'size': 'absolut_freq'})\n",
    "    )\n",
    "    counts = {'M': len(all_words_M), 'F': len(all_words_F)}\n",
    "    \n",
    "     # Arvutame tunnusõnasageduse tunnis\n",
    "    grouped['freq_per_1000_tokens'] = (grouped['absolut_freq']/ (grouped['gender'].map(counts) / 1000))\n",
    "\n",
    "    grouped.to_csv(output_path, sep=sep, index=False)\n",
    "    \n",
    "    print(f\"Saved {output_path}\")\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da80d67f-18da-458e-8e00-5b765d296495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tunnused_sections_csv/verbid_partiklitena_sections.csv\n",
      "Saved tunnused_sections_csv/esimese_ja_teise_isik_sections.csv\n",
      "Saved tunnused_sections_csv/partikkel_sections.csv\n",
      "Saved tunnused_sections_csv/kaskiv_sections.csv\n",
      "Saved tunnused_sections_csv/tingiv_sections.csv\n",
      "Saved tunnused_sections_csv/umbisikuline_sections.csv\n",
      "Saved tunnused_sections_csv/kp_markerid_sections.csv\n",
      "Saved tunnused_sections_csv/intensiivistajad_omadussonadega_sections.csv\n",
      "Saved tunnused_sections_csv/intensiivistajad_verbidega_sections.csv\n",
      "Saved tunnused_sections_csv/intensiivistajad_adverbidega_sections.csv\n",
      "Saved tunnused_sections_csv/eitused_sections.csv\n",
      "Saved tunnused_sections_csv/deminutiivid_sections.csv\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    ('tabelid_kontrollimiseks/verbid_partiklitena_kontrollitud_uus.csv',\n",
    "     'verbid_partiklitena_sections.csv', ';'),\n",
    "    ('tabelid_kontrollimiseks/esimese_ja_teise_isik.csv',\n",
    "     'esimese_ja_teise_isik_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/partiklid.csv',\n",
    "     'partikkel_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/kaskiv_kontrollitud.csv',\n",
    "     'kaskiv_sections.csv', ';'),\n",
    "    ('tabelid_kontrollimiseks/tingiv.csv',\n",
    "     'tingiv_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/umbisikuline.csv',\n",
    "     'umbisikuline_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/kp_markerid.csv',\n",
    "     'kp_markerid_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/intensiivistajad_omadussonadega.csv',\n",
    "     'intensiivistajad_omadussonadega_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/intensiivistajad_verbidega.csv',\n",
    "     'intensiivistajad_verbidega_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/intensiivistajad_adverbidega.csv',\n",
    "     'intensiivistajad_adverbidega_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/eitused.csv',\n",
    "     'eitused_sections.csv', ','),\n",
    "    ('tabelid_kontrollimiseks/deminutiivid.csv',\n",
    "     'deminutiivid_sections.csv', ',')\n",
    "]\n",
    "\n",
    "output_dir = 'tunnused_sections_csv/' #vaata GitHubis tunnused kausta\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for input_path, output_file, sep in tasks:\n",
    "    out_path = os.path.join(output_dir, output_file)\n",
    "    df = aggregate_section_counts(\n",
    "        input_path=input_path,\n",
    "        output_path=out_path,\n",
    "        sep=sep,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f58b6d3a-ae8c-423d-8002-8017fbf4d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tables_per_feature(\n",
    "    csv_path: str,\n",
    "    column_name: str,\n",
    "    out_dir: str,\n",
    "    threshold: int = None,\n",
    "    delimiter: str = ',',\n",
    "    encoding: str = 'utf-8'\n",
    "):\n",
    "    \"\"\"\n",
    "    Loeb CSV, rühmitab väärtuse järgi ja salvestab iga väärtuse CSV-failina.\n",
    "\n",
    "    Parameetrid:\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Tee sisend-CSV-failile.\n",
    "    column_name : str\n",
    "        Veeru nimi, mille alusel rühmitada.\n",
    "    out_dir : str\n",
    "        Väljundkataloog, kuhu failid salvestada.\n",
    "    threshold : int, valikuline\n",
    "        Minimaalne ridade arv väärtuse kohta, et salvestada (vaikimisi None).\n",
    "    delimiter : str, valikuline\n",
    "        CSV eraldaja (vaikimisi ',').\n",
    "    encoding : str, valikuline\n",
    "        Faili kodeering (vaikimisi 'utf-8').\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, sep=delimiter, encoding=encoding)\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for part_value, group in df.groupby(column_name):\n",
    "        if threshold is not None and len(group) <= threshold:\n",
    "            continue\n",
    "\n",
    "        safe = re.sub(r'[^\\w\\-]+', '_', str(part_value)).strip('_')\n",
    "        filename = f\"{safe}.csv\"\n",
    "\n",
    "        path = os.path.join(out_dir, filename)\n",
    "        group.to_csv(path, index=False)\n",
    "        print(f\"Salvestatud {len(group)} read → {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc4b503b-c94d-4c62-a0e4-dbbfcf96e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section_freq_tables(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    group_cols=('episode_id', 'section_index', 'gender', 'minutes'),\n",
    "    input_sep=',',\n",
    "    output_sep=';'\n",
    "):\n",
    "    \"\"\"\n",
    "    Loeb iga CSV-fail input_dir, rühmitab group_cols järgi ja arvutab sageduse.\n",
    "    Salvestab uued CSV-failid output_dir.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pattern = os.path.join(input_dir, '*.csv')\n",
    "    for in_path in glob.glob(pattern):\n",
    "\n",
    "        df = pd.read_csv(in_path, sep=input_sep)\n",
    "        \n",
    "        grouped = (\n",
    "            df\n",
    "            .groupby(list(group_cols), as_index=False)\n",
    "            .size()\n",
    "            .rename(columns={'size': 'absolut_freq'})\n",
    "        )\n",
    "        # Arvuta freq_per_hour või säilita absoluutfreq kui pole kestust\n",
    "        \n",
    "        counts = {'M': len(all_words_M), 'F': len(all_words_F)}\n",
    "    \n",
    "        \n",
    "        grouped['freq_per_1000_tokens'] = (grouped['absolut_freq']/ (grouped['gender'].map(counts) / 1000))\n",
    "        \n",
    "        \n",
    "        base = os.path.splitext(os.path.basename(in_path))[0]\n",
    "        out_name = f\"{base}_sections.csv\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "        grouped.to_csv(out_path, index=False, sep=output_sep)\n",
    "        print(f\"Salvestatud {len(grouped)} read → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a75a7877-2715-45b7-af9b-51edd9972952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 499 read → particles_per_value/eks_ole.csv\n",
      "Salvestatud 111 read → particles_per_value/jah.csv\n",
      "Salvestatud 127 read → particles_per_value/jumal.csv\n",
      "Salvestatud 59 read → particles_per_value/kurat.csv\n",
      "Salvestatud 10948 read → particles_per_value/nagu.csv\n",
      "Salvestatud 668 read → particles_per_value/no.csv\n",
      "Salvestatud 575 read → particles_per_value/noh.csv\n",
      "Salvestatud 58 read → particles_per_value/oh.csv\n",
      "Salvestatud 349 read → particles_per_value/okei.csv\n",
      "Salvestatud 133 read → particles_per_value/vot.csv\n",
      "Salvestatud 81 read → particles_per_value/sections_particles_per_value/jah_sections.csv\n",
      "Salvestatud 88 read → particles_per_value/sections_particles_per_value/jumal_sections.csv\n",
      "Salvestatud 146 read → particles_per_value/sections_particles_per_value/okei_sections.csv\n",
      "Salvestatud 475 read → particles_per_value/sections_particles_per_value/nagu_sections.csv\n",
      "Salvestatud 71 read → particles_per_value/sections_particles_per_value/vot_sections.csv\n",
      "Salvestatud 183 read → particles_per_value/sections_particles_per_value/noh_sections.csv\n",
      "Salvestatud 118 read → particles_per_value/sections_particles_per_value/eks_ole_sections.csv\n",
      "Salvestatud 44 read → particles_per_value/sections_particles_per_value/oh_sections.csv\n",
      "Salvestatud 36 read → particles_per_value/sections_particles_per_value/kurat_sections.csv\n",
      "Salvestatud 210 read → particles_per_value/sections_particles_per_value/no_sections.csv\n",
      "Salvestatud 1004 read → kp_markerid_per_value/arvama.csv\n",
      "Salvestatud 97 read → kp_markerid_per_value/lootma.csv\n",
      "Salvestatud 288 read → kp_markerid_per_value/tunduma.csv\n",
      "Salvestatud 142 read → kp_markerid_per_value/uskuma.csv\n",
      "Salvestatud 922 read → kp_markerid_per_value/ütlema.csv\n",
      "Salvestatud 224 read → kp_markerid_per_value/sections_kp_markerid_per_value/ütleme_sections.csv\n",
      "Salvestatud 146 read → kp_markerid_per_value/sections_kp_markerid_per_value/tundub_sections.csv\n",
      "Salvestatud 224 read → kp_markerid_per_value/sections_kp_markerid_per_value/ütlema_sections.csv\n",
      "Salvestatud 93 read → kp_markerid_per_value/sections_kp_markerid_per_value/uskuma_sections.csv\n",
      "Salvestatud 70 read → kp_markerid_per_value/sections_kp_markerid_per_value/loodan_sections.csv\n",
      "Salvestatud 255 read → kp_markerid_per_value/sections_kp_markerid_per_value/arvan_sections.csv\n",
      "Salvestatud 93 read → kp_markerid_per_value/sections_kp_markerid_per_value/usun_sections.csv\n",
      "Salvestatud 70 read → kp_markerid_per_value/sections_kp_markerid_per_value/lootma_sections.csv\n",
      "Salvestatud 146 read → kp_markerid_per_value/sections_kp_markerid_per_value/tunduma_sections.csv\n",
      "Salvestatud 255 read → kp_markerid_per_value/sections_kp_markerid_per_value/arvama_sections.csv\n",
      "Salvestatud 86 read → intensiivistajad_per_value/absoluutselt.csv\n",
      "Salvestatud 124 read → intensiivistajad_per_value/eriti.csv\n",
      "Salvestatud 960 read → intensiivistajad_per_value/hästi.csv\n",
      "Salvestatud 2003 read → intensiivistajad_per_value/kui.csv\n",
      "Salvestatud 201 read → intensiivistajad_per_value/liiga.csv\n",
      "Salvestatud 301 read → intensiivistajad_per_value/natuke.csv\n",
      "Salvestatud 215 read → intensiivistajad_per_value/natukene.csv\n",
      "Salvestatud 2008 read → intensiivistajad_per_value/nii.csv\n",
      "Salvestatud 737 read → intensiivistajad_per_value/palju.csv\n",
      "Salvestatud 553 read → intensiivistajad_per_value/päris.csv\n",
      "Salvestatud 97 read → intensiivistajad_per_value/suht.csv\n",
      "Salvestatud 77 read → intensiivistajad_per_value/suhteliselt.csv\n",
      "Salvestatud 319 read → intensiivistajad_per_value/täiesti.csv\n",
      "Salvestatud 109 read → intensiivistajad_per_value/täitsa.csv\n",
      "Salvestatud 324 read → intensiivistajad_per_value/tõesti.csv\n",
      "Salvestatud 2892 read → intensiivistajad_per_value/väga.csv\n",
      "Salvestatud 495 read → intensiivistajad_per_value/üldse.csv\n",
      "Salvestatud 140 read → intensiivistajad_per_value/üsna.csv\n",
      "Salvestatud 208 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/päris_sections.csv\n",
      "Salvestatud 108 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/liiga_sections.csv\n",
      "Salvestatud 72 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/üsna_sections.csv\n",
      "Salvestatud 55 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/absoluutselt_sections.csv\n",
      "Salvestatud 203 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/üldse_sections.csv\n",
      "Salvestatud 91 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/eriti_sections.csv\n",
      "Salvestatud 146 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/täiesti_sections.csv\n",
      "Salvestatud 227 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/palju_sections.csv\n",
      "Salvestatud 369 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/kui_sections.csv\n",
      "Salvestatud 143 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/natuke_sections.csv\n",
      "Salvestatud 222 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/hästi_sections.csv\n",
      "Salvestatud 118 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/natukene_sections.csv\n",
      "Salvestatud 135 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/tõesti_sections.csv\n",
      "Salvestatud 52 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/suhteliselt_sections.csv\n",
      "Salvestatud 346 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/nii_sections.csv\n",
      "Salvestatud 63 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/täitsa_sections.csv\n",
      "Salvestatud 54 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/suht_sections.csv\n",
      "Salvestatud 380 read → intensiivistajad_per_value/sections_intensiivistajad_per_value/väga_sections.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Kõikide kogumite standardkünnis\n",
    "    threshold = 50\n",
    "\n",
    "    # Andmekogumid: (CSV-fail, grupeerimise veerg, väljundkataloog)\n",
    "    datasets = [\n",
    "        (\n",
    "            'tabelid_kontrollimiseks/partiklid.csv',\n",
    "            'tunnus',\n",
    "            'particles_per_value'   #vaata GitHubis partiklid kausta\n",
    "        ),\n",
    "\n",
    "        (\n",
    "            'tabelid_kontrollimiseks/kp_markerid.csv',\n",
    "            'tunnus',\n",
    "            'kp_markerid_per_value' #vaata GitHubis kp-markerid kausta\n",
    "        ),\n",
    "        (\n",
    "            'tabelid_kontrollimiseks/intensiivistajad.csv',\n",
    "            'tunnus',\n",
    "            'intensiivistajad_per_value'       #vaata GitHubis intensiivistajad kausta\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    for csv_path, column_name, out_dir in datasets:\n",
    "        # 1) Salvestame tabelid väärtuste kaupa\n",
    "        save_tables_per_feature(\n",
    "            csv_path=csv_path,\n",
    "            column_name=column_name,\n",
    "            out_dir=out_dir,\n",
    "            threshold=threshold\n",
    "        )\n",
    "\n",
    "        # 2) Sektsioonide sagedustabelite genereerimine\n",
    "        sections_dir = Path(out_dir) / f\"sections_{Path(out_dir).name}\"\n",
    "        make_section_freq_tables(\n",
    "            input_dir=out_dir,\n",
    "            output_dir=str(sections_dir)\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

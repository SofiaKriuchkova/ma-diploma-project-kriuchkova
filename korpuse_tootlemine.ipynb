{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37bb96cc-dc65-4a07-bfbf-0c481c92c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from estnltk import Text\n",
    "from estnltk.converters import json_to_text\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac6da65-a72f-42f0-8483-81dead18a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopid_fail = 'estonian-stopwords.txt'\n",
    "lemmad_fail = 'estonian-stopwords-lemmas.txt'\n",
    "\n",
    "stopid_s = []\n",
    "with open(stopid_fail, 'r') as sf:\n",
    "    for line in sf:\n",
    "        stopid_s.append(line.strip())\n",
    "\n",
    "stopid_l = []\n",
    "with open(lemmad_fail, 'r') as lf:\n",
    "    for line in lf:\n",
    "        stopid_l.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aea19a2-b725-4484-900a-4135be310e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_jsonist(dir):\n",
    "\n",
    "    sekundid = 0\n",
    "    koik_konet = []\n",
    "    \n",
    "    for fail in os.listdir(dir):\n",
    "        f_nimi = os.path.join(dir, fail)\n",
    "        if not fail.endswith('.json'):\n",
    "            continue\n",
    "        with open(f_nimi, 'r') as f:\n",
    "       \n",
    "            andmed = json.load(f)\n",
    "     \n",
    "            for section in andmed['sections']:\n",
    "                if 'turns' in section.keys():\n",
    "                    algus = float(section['start'])\n",
    "                    lopp = float(section['end'])\n",
    "                    aeg_kokku = lopp - algus\n",
    "                    sekundid += aeg_kokku\n",
    "\n",
    "                    for turn in section['turns']:\n",
    "                        kone = turn['transcript']\n",
    "                        koik_konet.append(kone)\n",
    "\n",
    "    return sekundid/60, ' '.join(koik_konet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e26d12f-f2b1-4cd0-9c8c-ffb3e44d9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loendamine(kone):\n",
    "    \n",
    "    \n",
    "    koik_sonad = []\n",
    "    koik_lemmad = []\n",
    "    \n",
    "    tekst = Text(kone).tag_layer('morph_analysis')\n",
    "    for sone in tekst.morph_analysis:\n",
    "        lemma = sone.lemma[0].lower()\n",
    "        soneliik = sone.partofspeech[0]\n",
    "                        \n",
    "        if soneliik != 'Z':\n",
    "            koik_lemmad.append(lemma)\n",
    "            koik_sonad.append(sone.text.lower())\n",
    "            \n",
    "    return koik_sonad, koik_lemmad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b21ee2c-986a-4fd8-86e8-bc7b111ca552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sagedus_loend(lemmad, stop_sonad):\n",
    "    freq_counter = Counter()\n",
    "    for lemma in lemmad:\n",
    "        if lemma not in stop_sonad:\n",
    "            freq_counter[lemma] += 1\n",
    "\n",
    "    return freq_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b6c7096-84bf-4c2d-8c6f-4ab5d0fdaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2590.5986666666695\n"
     ]
    }
   ],
   "source": [
    "minutid_mehed, kone_mehed = speech_jsonist('mehed')\n",
    "print(minutid_mehed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54de7b5-d87f-4523-9a46-cf538a38d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010.3988333333323\n"
     ]
    }
   ],
   "source": [
    "minutid_naised, kone_naised = speech_jsonist('naised')\n",
    "print(minutid_naised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c9ecd1-ab4d-476c-9dfe-cd98fa204b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.17664444444449\n"
     ]
    }
   ],
   "source": [
    "print(minutid_mehed/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a493d629-664b-4b97-b0e4-9b22b80bea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.506647222222206\n"
     ]
    }
   ],
   "source": [
    "print(minutid_naised/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7b16eb-b97b-4f1b-85ad-2fc40061d5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "koik_sonad_mehed, koik_lemmad_mehed = loendamine(kone_mehed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "030e9445-c500-493e-978a-7bc305d9d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "koik_sonad_naised, koik_lemmad_naised = loendamine(kone_naised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210e8a4-402a-4add-97b2-bee45b6426c3",
   "metadata": {},
   "source": [
    "Sagedusloendid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1721e6-624a-430b-91f8-6b0bfd707ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sageduse_fail(failinimi, loend, minutid):\n",
    "    with open(failinimi, 'w', encoding='utf-8', newline='') as out_f:\n",
    "        writer = csv.writer(out_f, delimiter=';')\n",
    "    \n",
    "  \n",
    "        writer.writerow(['lemma', 'raw_count', 'freq_per_60_min'])\n",
    "\n",
    "        for lemma, cnt in loend.most_common():\n",
    "            freq_per_1000 = (cnt / minutid) * 60\n",
    "            writer.writerow([lemma, cnt, f\"{freq_per_1000:.3f}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684a9ee2-a27c-4381-ac81-80fb4995655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out = 'lemmade_sagedus_by_min_mehed_veel.csv'\n",
    "\n",
    "sageduse_fail(filename_out, sagedus_loend(koik_lemmad_mehed, stopid_l), minutid_mehed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc5a975-b432-4618-9826-3b9876d8041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_out = 'lemmade_sagedus_by_min_naised_veel.csv'\n",
    "\n",
    "sageduse_fail(filename_out, sagedus_loend(koik_lemmad_naised, stopid_l), minutid_naised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85343f08-d095-4221-99ff-a4a9a66453c6",
   "metadata": {},
   "source": [
    "Bigrammid ja trigrammid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b80e3c-37fd-4fe0-8bde-cc2f8a349a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_ja_tri_grammid(lemmad, stop_lemmad, sonad, stop_sonad):\n",
    "\n",
    "    bigram_counter_lemma = Counter()\n",
    "    trigram_counter_lemma = Counter()\n",
    "    \n",
    "    for i in range(len(lemmad)-1):\n",
    "        bigram = (lemmad[i].lower(), lemmad[i+1].lower())\n",
    "        if bigram[0] != bigram[1]:\n",
    "    \n",
    "            if bigram[0] not in stop_lemmad and bigram[1] not in stop_lemmad:\n",
    "                bigram_counter_lemma[bigram] += 1\n",
    "            elif bigram[1] not in stop_lemmad:\n",
    "                bigram_counter_lemma[bigram] += 1\n",
    "    \n",
    "    for i in range(len(lemmad) - 2):\n",
    "        w1 = lemmad[i].lower()\n",
    "        w2 = lemmad[i+1].lower()\n",
    "        w3 = lemmad[i+2].lower()\n",
    "        \n",
    "\n",
    "        if w1 != w2 and w2 != w3 and w1 != w3:\n",
    "            if w1 not in stop_lemmad and w2 not in stop_lemmad and w3 not in stop_lemmad:\n",
    "                trigram = (w1, w2, w3)\n",
    "                trigram_counter_lemma[trigram] += 1\n",
    "            elif w1 not in stop_lemmad and  w3 not in stop_lemmad:\n",
    "                trigram = (w1, w2, w3)\n",
    "                trigram_counter_lemma[trigram] += 1\n",
    "    \n",
    "    print(\"Top 10 bigrams (lemmas):\")\n",
    "    for bg, cnt in bigram_counter_lemma.most_common(10):\n",
    "        print(bg, cnt)\n",
    "        \n",
    "    print(\"\\nTop 10 trigrams (lemmas):\")\n",
    "    for tg, cnt in trigram_counter_lemma.most_common(10):\n",
    "        print(tg, cnt)\n",
    "    \n",
    "\n",
    "    bigram_counter_raw = Counter()\n",
    "    trigram_counter_raw = Counter()\n",
    "    \n",
    "    for i in range(len(sonad)-1):\n",
    "        bigram = (sonad[i].lower(), sonad[i+1].lower())\n",
    "        if bigram[0] != bigram[1]:\n",
    "            if bigram[0] not in stop_sonad and bigram[1] not in stop_sonad:\n",
    "                bigram_counter_raw[bigram] += 1\n",
    "            elif bigram[1] not in stop_sonad:\n",
    "                bigram_counter_raw[bigram] += 1\n",
    "    \n",
    "    for i in range(len(sonad) - 2):\n",
    "        w1 = sonad[i].lower()\n",
    "        w2 = sonad[i+1].lower()\n",
    "        w3 = sonad[i+2].lower()\n",
    "        \n",
    "\n",
    "        if w1 != w2 and w2 != w3 and w1 != w3:\n",
    "            if w1 not in stop_sonad and w2 not in stop_sonad and w3 not in stop_sonad:\n",
    "                trigram = (w1, w2, w3)\n",
    "                trigram_counter_raw[trigram] += 1\n",
    "            elif w1 not in stop_sonad and  w3 not in stop_sonad:\n",
    "                trigram = (w1, w2, w3)\n",
    "                trigram_counter_raw[trigram] += 1\n",
    "    \n",
    "    print(\"\\nTop 10 bigrams (raw forms):\")\n",
    "    for bg, cnt in bigram_counter_raw.most_common(10):\n",
    "        print(bg, cnt)\n",
    "        \n",
    "    print(\"\\nTop 10 trigrams (raw forms):\")\n",
    "    for tg, cnt in trigram_counter_raw.most_common(10):\n",
    "        print(tg, cnt)\n",
    "    return bigram_counter_lemma, trigram_counter_lemma, bigram_counter_raw, trigram_counter_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e65092e7-d8b1-4b71-a8c5-e5b18ea15633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bigrams (lemmas):\n",
      "('ei', 'teadma') 854\n",
      "('mina', 'arvama') 656\n",
      "('see', 'mõte') 531\n",
      "('mina', 'ütlema') 346\n",
      "('see', 'asi') 302\n",
      "('saama', 'aru') 298\n",
      "('mina', 'tahtma') 289\n",
      "('mina', 'arust') 273\n",
      "('kogu', 'aeg') 236\n",
      "('mina', 'rääkima') 182\n",
      "\n",
      "Top 10 trigrams (lemmas):\n",
      "('eesti', 'puue', 'inimene') 28\n",
      "('puue', 'inimene', 'koda') 27\n",
      "('mees', 'ei', 'nutma') 20\n",
      "('no', 'see', 'mõte') 17\n",
      "('teadma', 'mis', 'asi') 13\n",
      "('no', 'mina', 'ütlema') 12\n",
      "('jutt', 'roheline', 'stuudio') 10\n",
      "('ütlema', 'et', 'kuulma') 10\n",
      "('tõde', 'ja', 'õigus') 9\n",
      "('no', 'mina', 'arvama') 9\n",
      "\n",
      "Top 10 bigrams (raw forms):\n",
      "('ei', 'tea') 793\n",
      "('ma', 'arvan') 597\n",
      "('selles', 'mõttes') 467\n",
      "('minu', 'arust') 272\n",
      "('kogu', 'aeg') 234\n",
      "('ma', 'ütlen') 145\n",
      "('see', 'ongi') 127\n",
      "('väga', 'hea') 122\n",
      "('ma', 'tean') 122\n",
      "('saan', 'aru') 118\n",
      "\n",
      "Top 10 trigrams (raw forms):\n",
      "('eesti', 'puuetega', 'inimeste') 22\n",
      "('mehed', 'ei', 'nuta') 18\n",
      "('no', 'selles', 'mõttes') 17\n",
      "('jutud', 'rohelises', 'stuudios') 10\n",
      "('no', 'ma', 'arvan') 9\n",
      "('puuetega', 'inimeste', 'kojas') 8\n",
      "('puuetega', 'inimeste', 'koja') 8\n",
      "('no', 'ma', 'ütlen') 8\n",
      "('konsultant', 'ja', 'koolitaja') 6\n",
      "('tegelikult', 'ma', 'arvan') 6\n"
     ]
    }
   ],
   "source": [
    "bigrammid_lem_mehed, trigrammid_lem_mehed, bigrammid_raw_mehed, trigrammid_raw_mehed = bi_ja_tri_grammid(koik_lemmad_mehed, \n",
    "                                                                                                         stopid_l, koik_sonad_mehed, stopid_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "947a3404-f2eb-4a5f-af98-1fc0495a8cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 bigrams (lemmas):\n",
      "('ei', 'teadma') 446\n",
      "('mina', 'arvama') 374\n",
      "('see', 'mõte') 300\n",
      "('mina', 'tahtma') 291\n",
      "('olema', 'tegelikult') 229\n",
      "('mina', 'ütlema') 226\n",
      "('mina', 'rääkima') 212\n",
      "('see', 'inimene') 209\n",
      "('olema', 'hästi') 201\n",
      "('olema', 'vaja') 180\n",
      "\n",
      "Top 10 trigrams (lemmas):\n",
      "('tartu', 'noorsootöö', 'keskus') 19\n",
      "('mees', 'ja', 'naine') 13\n",
      "('noor', 'vaimne', 'tervis') 11\n",
      "('ütlema', 'et', 'kuulma') 10\n",
      "('hästi', 'palju', 'erinev') 9\n",
      "('ema', 'ja', 'isa') 8\n",
      "('teinekord', 'ikka', 'jälle') 8\n",
      "('no', 'mina', 'arvama') 8\n",
      "('no', 'mina', 'ütlema') 8\n",
      "('puudutama', 'mina', 'saade') 7\n",
      "\n",
      "Top 10 bigrams (raw forms):\n",
      "('ei', 'tea') 415\n",
      "('ma', 'arvan') 337\n",
      "('selles', 'mõttes') 274\n",
      "('et', 'tegelikult') 173\n",
      "('kogu', 'aeg') 159\n",
      "('on', 'tegelikult') 158\n",
      "('on', 'hästi') 144\n",
      "('ma', 'tahan') 136\n",
      "('on', 'vaja') 128\n",
      "('me', 'räägime') 117\n",
      "\n",
      "Top 10 trigrams (raw forms):\n",
      "('tartu', 'noorsootöö', 'keskuse') 10\n",
      "('vaatasite', 'vaadake', 'teinekord') 9\n",
      "('teinekord', 'ikka', 'jälle') 8\n",
      "('no', 'ma', 'arvan') 8\n",
      "('hästi', 'palju', 'erinevaid') 7\n",
      "('head', 'uut', 'aastat') 7\n",
      "('no', 'selles', 'mõttes') 6\n",
      "('aru', 'et', 'okei') 6\n",
      "('varem', 'või', 'hiljem') 6\n",
      "('hästi', 'kuulmiseni', 'nägemiseni') 6\n"
     ]
    }
   ],
   "source": [
    "bigrammid_lem_naised, trigrammid_lem_naised, bigrammid_raw_naised, trigrammid_raw_naised = bi_ja_tri_grammid(koik_lemmad_naised, \n",
    "                                                                                                             stopid_l, koik_sonad_naised, stopid_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f445624-c8d4-41da-aa7a-102de263c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_ja_tri_failid(filename_bigrams_lemma, filename_trigrams_lemma, filename_bigrams_raw, filename_trigrams_raw, \n",
    "                    bigram_counter_lemma, trigram_counter_lemma, bigram_counter_raw, trigram_counter_raw, total_minutes):\n",
    "   \n",
    "    with open(filename_bigrams_lemma, 'w', encoding='utf-8', newline='') as out_f:\n",
    "        writer = csv.writer(out_f, delimiter=';')\n",
    "\n",
    "        writer.writerow(['ngram', 'count', 'freq_per_60_min'])\n",
    "        \n",
    "        for bg, cnt in bigram_counter_lemma.most_common():\n",
    "\n",
    "            freq_1000 = (cnt / total_minutes) * 60  \n",
    "            \n",
    "\n",
    "            bg_str = ' '.join(bg)\n",
    "            \n",
    "\n",
    "            writer.writerow([bg_str, cnt, f\"{freq_1000:.4f}\"])\n",
    "    \n",
    "    with open(filename_trigrams_lemma, 'w', encoding='utf-8', newline='') as out_f:\n",
    "        writer = csv.writer(out_f, delimiter=';')\n",
    "\n",
    "        writer.writerow(['ngram', 'count', 'freq_per_60_min'])\n",
    "        \n",
    "        for tg, cnt in trigram_counter_lemma.most_common():\n",
    "\n",
    "            freq_1000 = (cnt / total_minutes) * 60  \n",
    "\n",
    "            tg_str = ' '.join(tg)\n",
    "            \n",
    "\n",
    "            writer.writerow([tg_str, cnt, f\"{freq_1000:.4f}\"])\n",
    "    \n",
    "    with open(filename_bigrams_raw, 'w', encoding='utf-8', newline='') as out_f:\n",
    "        writer = csv.writer(out_f, delimiter=';')\n",
    "\n",
    "        writer.writerow(['ngram', 'count', 'freq_per_60_min'])\n",
    "        \n",
    "        for bg, cnt in bigram_counter_raw.most_common():\n",
    "\n",
    "            freq_1000 = (cnt / total_minutes) * 60  \n",
    "            \n",
    "\n",
    "            bg_str = ' '.join(bg)\n",
    "            \n",
    "\n",
    "            writer.writerow([bg_str, cnt, f\"{freq_1000:.4f}\"])\n",
    "    \n",
    "    with open(filename_trigrams_raw, 'w', encoding='utf-8', newline='') as out_f:\n",
    "        writer = csv.writer(out_f, delimiter=';')\n",
    " \n",
    "        writer.writerow(['ngram', 'count', 'freq_per_60_min'])\n",
    "        \n",
    "        for tg, cnt in trigram_counter_raw.most_common():\n",
    "            freq_1000 = (cnt / total_minutes) * 60 \n",
    "            \n",
    "\n",
    "            tg_str = ' '.join(tg)\n",
    "            \n",
    "            writer.writerow([tg_str, cnt, f\"{freq_1000:.4f}\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4dfaec9-1d7c-4d7f-8e89-d8d8d5c3c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_bigrams_lemma_mehed = 'n_grammid/bigrams_lemma_per_60_minutes_mehed.csv'\n",
    "filename_trigrams_lemma_mehed = 'n_grammid/trigrams_lemma_per_60_minutes_mehed.csv'\n",
    "filename_bigrams_raw_mehed = 'n_grammid/bigrams_raw_per_60_minutes_mehed.csv'\n",
    "filename_trigrams_raw_mehed = 'n_grammid/trigrams_raw_per_60_minutes_mehed.csv'\n",
    "\n",
    "filename_bigrams_lemma_naised = 'n_grammid/bigrams_lemma_per_60_minutes_naised.csv'\n",
    "filename_trigrams_lemma_naised = 'n_grammid/trigrams_lemma_per_60_minutes_naised.csv'\n",
    "filename_bigrams_raw_naised = 'n_grammid/bigrams_raw_per_60_minutes_naised.csv'\n",
    "filename_trigrams_raw_naised = 'n_grammid/trigrams_raw_per_60_minutes_naised.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a8e3aae-e80c-4d47-a18e-8e3e0db14860",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_ja_tri_failid(filename_bigrams_lemma_mehed, filename_trigrams_lemma_mehed, filename_bigrams_raw_mehed, filename_trigrams_raw_mehed, \n",
    "                    bigrammid_lem_mehed, trigrammid_lem_mehed, bigrammid_raw_mehed, trigrammid_raw_mehed, minutid_mehed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "078f8baa-9ad7-4197-9a59-dcc5fd6f9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_ja_tri_failid(filename_bigrams_lemma_naised, filename_trigrams_lemma_naised, filename_bigrams_raw_naised, filename_trigrams_raw_naised, \n",
    "                    bigrammid_lem_naised, trigrammid_lem_naised, bigrammid_raw_naised, trigrammid_raw_naised, minutid_naised)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976984a3-20f1-4763-9a1d-39b2dadbd4b0",
   "metadata": {},
   "source": [
    "Sõnaliigid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0eeae7f-212f-484a-bcc8-ff978386e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_sections(dir_path, gender_tag):\n",
    "    records = []\n",
    "    for fname in os.listdir(dir_path):\n",
    "        if not fname.endswith('.json'):\n",
    "            continue\n",
    "        path = os.path.join(dir_path, fname)\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        episode_id = fname.replace('.json', '')\n",
    "        for idx, section in enumerate(data.get('sections', [])):\n",
    "            turns = section.get('turns')\n",
    "            if not turns:\n",
    "                continue\n",
    "            start, end = float(section['start']), float(section['end'])\n",
    "            minutes = (end - start) / 60.0\n",
    "            transcript = ' '.join(t['transcript'] for t in turns)\n",
    "            records.append({\n",
    "                'episode_id': episode_id,\n",
    "                'section_index': idx,\n",
    "                'gender': gender_tag,\n",
    "                'minutes': minutes,\n",
    "                'transcript': transcript\n",
    "            })\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e68c129-58fb-4f34-b352-43703e9dc876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos(text_str, skip_lemmas):\n",
    "    txt = Text(text_str)\n",
    "    txt.tag_layer('morph_analysis')\n",
    "    counters = {\n",
    "        'omadussõnad': Counter(),\n",
    "        'nimisõnad':   Counter(),\n",
    "        'adverbid':    Counter(),\n",
    "        'verbid':      Counter(),\n",
    "        'asesõnad':    Counter(),\n",
    "        'kaassõnad':   Counter(),\n",
    "    }\n",
    "    tag_map = {\n",
    "        'A': 'omadussõnad',\n",
    "        'S': 'nimisõnad',\n",
    "        'D': 'adverbid',\n",
    "        'V': 'verbid',\n",
    "        'P': 'asesõnad',\n",
    "        'K': 'kaassõnad'\n",
    "    }\n",
    "\n",
    "    for token in txt.morph_analysis:\n",
    "        tag = token.partofspeech[0]\n",
    "        if tag == 'V' and token.lemma[0].lower() in skip_lemmas:\n",
    "            continue\n",
    "        if tag in tag_map:\n",
    "            key = tag_map[tag]\n",
    "            form = token.lemma[0].lower()\n",
    "            counters[key][form] += 1\n",
    "    return counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ddc6a55-2bf0-4e3e-bfe5-3e723d1068b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "men_sections = speech_sections('mehed', 'M')\n",
    "women_sections = speech_sections('naised', 'F')\n",
    "all_sections = men_sections + women_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d901de8-fb21-4eb6-b1f6-9dd10ef8bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 15372 rows to pos_sections_csv/omadussõnad_by_section.csv\n",
      "Saved 58898 rows to pos_sections_csv/nimisõnad_by_section.csv\n",
      "Saved 35801 rows to pos_sections_csv/adverbid_by_section.csv\n",
      "Saved 29373 rows to pos_sections_csv/verbid_by_section.csv\n",
      "Saved 8888 rows to pos_sections_csv/asesõnad_by_section.csv\n",
      "Saved 5426 rows to pos_sections_csv/kaassõnad_by_section.csv\n"
     ]
    }
   ],
   "source": [
    "eituse_partiklid = ['ei', 'ära']\n",
    "# DataFrame\n",
    "records = []\n",
    "for sec in all_sections:\n",
    "\n",
    "    counts = count_pos(sec['transcript'], eituse_partiklid)\n",
    "    for pos, counter in counts.items():\n",
    "        for form, cnt in counter.items():\n",
    "            freq = (cnt / sec['minutes']) * 60 if sec['minutes'] > 0 else 0.0\n",
    "            records.append({\n",
    "                'episode_id': sec['episode_id'],\n",
    "                'section_index': sec['section_index'],\n",
    "                'gender': sec['gender'],\n",
    "                'minutes': sec['minutes'],\n",
    "                'sõnaliik': pos,\n",
    "                'feature': form,\n",
    "                'raw_count': cnt,\n",
    "                'freq_per_60_min': freq\n",
    "            })\n",
    "\n",
    "df_sections_pos = pd.DataFrame(records)\n",
    "\n",
    "# CSV \n",
    "os.makedirs('pos_sections_csv', exist_ok=True)\n",
    "for pos in df_sections_pos['sõnaliik'].unique():\n",
    "    df_subset = df_sections_pos[df_sections_pos['sõnaliik'] == pos]\n",
    "    filename = f'pos_sections_csv/{pos}_by_section.csv'\n",
    "    df_subset.to_csv(filename, index=False)\n",
    "    print(f\"Salvestatud {len(df_subset)} read - {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58846e11-b1ac-4414-91bf-c3ebd83b4d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaassõnad_by_section.csv → pos_sections_csv/pos_sections_counter/kaassõnad_by_section.csv\n",
      "omadussõnad_by_section.csv → pos_sections_csv/pos_sections_counter/omadussõnad_by_section.csv\n",
      "verbid_by_section.csv → pos_sections_csv/pos_sections_counter/verbid_by_section.csv\n",
      "adverbid_by_section.csv → pos_sections_csv/pos_sections_counter/adverbid_by_section.csv\n",
      "nimisõnad_by_section.csv → pos_sections_csv/pos_sections_counter/nimisõnad_by_section.csv\n",
      "asesõnad_by_section.csv → pos_sections_csv/pos_sections_counter/asesõnad_by_section.csv\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'pos_sections_csv'\n",
    "output_dir = 'pos_sections_csv/pos_sections_counter'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for filepath in glob.glob(os.path.join(input_dir, '*.csv')):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    grouped = (\n",
    "        df\n",
    "        .drop(columns=['feature'])\n",
    "        .groupby(['episode_id', 'section_index', 'gender', 'minutes', 'sõnaliik'], as_index=False)\n",
    "        .agg({\n",
    "            'raw_count': 'sum',\n",
    "            'freq_per_60_min': 'sum'\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    filename = os.path.basename(filepath)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    grouped.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f'{filename} → {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a165f250-5195-4211-a98b-06f00e5cd830",
   "metadata": {},
   "outputs": [],
   "source": [
    "eituse_partiklid = ['ei', 'ära']\n",
    "es_ja_te_pronoomenid = ['mina', 'sina']\n",
    "tingiv_koneviis = ['ks', 'ksin', 'ksid', 'ksime', 'ksite', 'taks', 'nuksin', 'nuksid', 'nuks', 'nuksime', 'nuksite', 'tuks']\n",
    "umbisikuline = ['ti', 'takse', 'ti', 'tud', 'taks', 'tuks', 'tagu']\n",
    "kaskiv_koneviis = ['o', 'ge', 'gem']\n",
    "kp_markerid = ['arvan', 'usun', 'kardan', 'tundub', 'paistab', 'näib', 'loodan', 'ütleme']\n",
    "verbid_partiklidena = ['ootama', 'vaatama', 'kuulama', 'kuulma']\n",
    "\n",
    "intensiivistajad_loendist = []\n",
    "with open('intensiivistajad.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        intensiivistajad_loendist.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23ecef09-7afc-482b-82a7-4f07299531a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eitused = []\n",
    "esimese_ja_teise_isik = []\n",
    "intensiivistajad_omadussonadega = []\n",
    "intensiivistajad_verbidega = []\n",
    "intensiivistajad_adverbidega = []\n",
    "tingiv_koneviis_loend = []\n",
    "umbisikuline_loend = []\n",
    "kaskiv_koneviis_loend = []\n",
    "kp_markerid_loend = []\n",
    "verbid_partiklidena_loend = []\n",
    "\n",
    "\n",
    "for sec in all_sections:\n",
    "    plok = sec['transcript']\n",
    "\n",
    "    plok_nltk = Text(plok).tag_layer('morph_analysis')\n",
    "    for lause in plok_nltk.sentences:      \n",
    "        for i, sone in enumerate(lause):\n",
    "            if sone.lemma[0] in eituse_partiklid and lause[i+1].partofspeech[0] == 'V':\n",
    "                eitused.append({\n",
    "                    'episode_id': sec['episode_id'],\n",
    "                    'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'],\n",
    "                    'minutes': sec['minutes'],\n",
    "                    'eituse': sone.lemma[0],\n",
    "                    'verb': lause[i+1].lemma[0],\n",
    "                    'lause': \" \".join([sone.text for sone in lause])\n",
    "                })\n",
    "                \n",
    "            if sone.lemma[0] in es_ja_te_pronoomenid:\n",
    "                esimese_ja_teise_isik.append({\n",
    "                    'episode_id': sec['episode_id'],\n",
    "                    'section_index': sec['section_index'],\n",
    "                    'gender': sec['gender'],\n",
    "                    'minutes': sec['minutes'],\n",
    "                    'pronoomen': sone.text.lower(),\n",
    "                    'lause': \" \".join([sone.text for sone in lause])\n",
    "                })\n",
    "                \n",
    "            if sone.lemma[0] in intensiivistajad_loendist:\n",
    "                if lause[i+1].partofspeech[0] == 'A':\n",
    "                    intensiivistajad_omadussonadega.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'pos': lause[i+1].partofspeech[0],\n",
    "                        'inetnsiivistaja': sone.lemma[0],\n",
    "                        'sona': lause[i+1].lemma[0],\n",
    "                        'lause': \" \".join([sone.text for sone in lause])\n",
    "                    })\n",
    "                    \n",
    "                elif lause[i+1].partofspeech[0] == 'V':\n",
    "                    intensiivistajad_verbidega.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'pos': lause[i+1].partofspeech[0],\n",
    "                        'inetnsiivistaja': sone.lemma[0],\n",
    "                        'sona': lause[i+1].lemma[0],\n",
    "                        'lause': \" \".join([sone.text for sone in lause])\n",
    "                    })\n",
    "                elif lause[i+1].partofspeech[0] == 'D':\n",
    "                    intensiivistajad_adverbidega.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'pos': lause[i+1].partofspeech[0],\n",
    "                        'inetnsiivistaja': sone.lemma[0],\n",
    "                        'sona': lause[i+1].lemma[0],\n",
    "                        'lause': \" \".join([sone.text for sone in lause])\n",
    "                    })\n",
    "\n",
    "            if sone.partofspeech[0] == 'V':\n",
    "                if sone.text in kp_markerid:\n",
    "                    kp_markerid_loend.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'verb': sone.text,\n",
    "                        'lause': \" \".join([sone.text for sone in lause])\n",
    "                     })\n",
    "                if sone.form[0] in tingiv_koneviis:\n",
    "                    tingiv_koneviis_loend.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'verb': sone.text,\n",
    "                        'lause': \" \".join([sone.text for sone in lause])\n",
    "                    })\n",
    "                    \n",
    "                elif sone.form[0] in umbisikuline:\n",
    "                    umbisikuline_loend.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'verb': sone.text,\n",
    "                        'lause': \" \".join([sone.text for sone in lause])\n",
    "                    })\n",
    "                elif sone.form[0] in kaskiv_koneviis and lause[i-1].text.lower() not in ['ei', 'et']:\n",
    "                    if sone.lemma[0] in verbid_partiklidena:\n",
    "                        verbid_partiklidena_loend.append({\n",
    "                            'episode_id': sec['episode_id'],\n",
    "                            'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'],\n",
    "                            'minutes': sec['minutes'],\n",
    "                            'verb': sone.text,\n",
    "                            'lause': \" \".join([sone.text for sone in lause])\n",
    "                        })\n",
    "                    else:\n",
    "                        kaskiv_koneviis_loend.append({\n",
    "                            'episode_id': sec['episode_id'],\n",
    "                            'section_index': sec['section_index'],\n",
    "                            'gender': sec['gender'],\n",
    "                            'minutes': sec['minutes'],\n",
    "                            'verb': sone.text,\n",
    "                            'lause': \" \".join([sone.text for sone in lause])\n",
    "                         })\n",
    "\n",
    "df_eitused = pd.DataFrame(eitused)\n",
    "df_esimese_ja_teise_isik = pd.DataFrame(esimese_ja_teise_isik)\n",
    "df_intensiivistajad_omadussonadega = pd.DataFrame(intensiivistajad_omadussonadega)\n",
    "df_intensiivistajad_verbidega = pd.DataFrame(intensiivistajad_verbidega)\n",
    "df_intensiivistajad_adverbidega = pd.DataFrame(intensiivistajad_adverbidega)\n",
    "df_tingiv = pd.DataFrame(tingiv_koneviis_loend)\n",
    "df_umbisikuline = pd.DataFrame(umbisikuline_loend)\n",
    "df_kaskiv = pd.DataFrame(kaskiv_koneviis_loend)\n",
    "df_kp = pd.DataFrame(kp_markerid_loend)\n",
    "df_verbid_partiklidena = pd.DataFrame(verbid_partiklidena_loend)\n",
    "\n",
    "df_eitused.to_csv('tabelid_kontrollimiseks/eitused.csv', index=False)\n",
    "df_esimese_ja_teise_isik.to_csv('tabelid_kontrollimiseks/esimese_ja_teise_isik.csv', index=False)\n",
    "df_intensiivistajad_omadussonadega.to_csv('tabelid_kontrollimiseks/intensiivistajad_omdasusonadega.csv', index=False)\n",
    "df_intensiivistajad_verbidega.to_csv('tabelid_kontrollimiseks/intensiivistajad_verbidega.csv', index=False)\n",
    "df_intensiivistajad_adverbidega.to_csv('tabelid_kontrollimiseks/intensiivistajad_adverbidega.csv', index=False)\n",
    "df_tingiv.to_csv('tabelid_kontrollimiseks/tingiv.csv', index=False)\n",
    "df_umbisikuline.to_csv('tabelid_kontrollimiseks/umbisikuline.csv', index=False)\n",
    "df_kaskiv.to_csv('tabelid_kontrollimiseks/kaskiv.csv', index=False)\n",
    "df_kp.to_csv('tabelid_kontrollimiseks/kp_markerid.csv', index=False)\n",
    "df_verbid_partiklidena.to_csv('tabelid_kontrollimiseks/vaata_oota.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddc17dc6-e478-4dfe-8e28-1d5cc07c2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "partiklid = []\n",
    "for sec in all_sections:\n",
    "    plok = sec['transcript']\n",
    "\n",
    "    plok_nltk = Text(plok).tag_layer('morph_analysis')\n",
    "    for lause in plok_nltk.sentences:      \n",
    "        for i, sone in enumerate(lause):\n",
    "            if sone.partofspeech[0] == 'I' or sone.lemma[0] == 'nagu':\n",
    "                if sone.lemma[0] == 'tere':\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                if i-2 < 0 or i+2 >= len(lause):\n",
    "                    continue\n",
    "\n",
    "            \n",
    "                if (lause[i-2].text != sone.text) or (lause[i+2].text != sone.text):\n",
    "                    partiklid.append({\n",
    "                        'episode_id': sec['episode_id'],\n",
    "                        'section_index': sec['section_index'],\n",
    "                        'gender': sec['gender'],\n",
    "                        'minutes': sec['minutes'],\n",
    "                        'partikkel': sone.lemma[0],\n",
    "                        'lause': \" \".join([tok.text for tok in lause])\n",
    "                    })\n",
    "\n",
    "df_partiklid = pd.DataFrame(partiklid)  \n",
    "df_partiklid.to_csv('tabelid_kontrollimiseks/partiklid.csv', index=False)\n",
    "                #print(lause.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5622974c-4b07-4133-bd4b-abf105707f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tabelid_kontrollimiseks/vaata_oota.csv')\n",
    "\n",
    "\n",
    "particles = ['no', 'noh', 'nagu', 'aga', 'siis']\n",
    "particle_pat = r'(?:' + '|'.join(particles) + r')'  # (?:no|noh|nagu|aga|siis)\n",
    "\n",
    "def classify(row):\n",
    "    verb = re.escape(row['verb'])\n",
    "    text = row['lause']\n",
    "\n",
    "    # verbi rea alguses, millele järgneb koma\n",
    "    start_pattern = rf'(?i)^\\s*{verb}\\b\\s*,'\n",
    "    if re.match(start_pattern, text):\n",
    "        return 1\n",
    "\n",
    "    # või\n",
    "    any_pattern = (\n",
    "        rf'(?i)'                    \n",
    "        rf'\\b'                          # sõna piir\n",
    "        rf'(?:{particle_pat}\\s+)?'      # partikkel enne\n",
    "        rf'{verb}\\b'                    # verb\n",
    "        rf'(?:\\s+{particle_pat})?'      # partikkel pärast\n",
    "        rf'\\s*,'                        # tühikud (kui on), koma\n",
    "    )\n",
    "    return 1 if re.search(any_pattern, text) else 0\n",
    "\n",
    "df['mood_flag'] = df.apply(classify, axis=1)\n",
    "df.to_csv('tabelid_kontrollimiseks/verbid_partiklidena_kontrollimiseks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0059b-a8df-4c2a-94f0-dcba7a0cb9ce",
   "metadata": {},
   "source": [
    "Kui tabelid on kontrollitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a0d08ab-a427-423d-b979-2382df418989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud tabelid_kontrollimiseks/verbid_partiklidena_kontrollitud_uus.csv\n"
     ]
    }
   ],
   "source": [
    "input_path  = \"tabelid_kontrollimiseks/verbid_partiklidena_kontrollitud.csv\"\n",
    "output_path = \"tabelid_kontrollimiseks/verbid_partiklidena_kontrollitud_uus.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path, sep=\";\")\n",
    "df[\"mood_flag\"] = pd.to_numeric(df[\"mood_flag\"], errors=\"coerce\")\n",
    "df_clean = df[df[\"mood_flag\"] != 0]\n",
    "df_clean.to_csv(output_path, sep=\";\", index=False)\n",
    "\n",
    "print(f\"Salvestatud {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da80d67f-18da-458e-8e00-5b765d296495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud tabelid_kontrollimiseks/sections/esimese_ja_teise_isik_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/partikkel_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/kaskiv_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/tingiv_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/umbisikuline_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/kp_markerid_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/umbisikuline_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/intensiivistajad_omadussonadega_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/intensiivistajad_verbidega_sections.csv\n",
      "Salvestatud tabelid_kontrollimiseks/sections/intensiivistajad_adverbidega_sections.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def aggregate_section_counts(\n",
    "    input_path: str,\n",
    "    output_path: str,\n",
    "    sep: str = ';',\n",
    "    group_cols: list = None\n",
    ") -> pd.DataFrame:\n",
    "   \n",
    "    df = pd.read_csv(input_path, sep=sep)\n",
    "    \n",
    "   \n",
    "    if group_cols is None:\n",
    "        group_cols = ['episode_id', 'section_index', 'gender', 'minutes']\n",
    "    \n",
    "\n",
    "    grouped = (\n",
    "        df\n",
    "        .groupby(group_cols, as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={'size': 'absolut_freq'})\n",
    "    )\n",
    "    \n",
    "\n",
    "    grouped['freq_per_hour'] = grouped['absolut_freq'] / (grouped['minutes'] / 60)\n",
    "    \n",
    "\n",
    "    grouped.to_csv(output_path, sep=sep, index=False)\n",
    "    \n",
    "    print(f\"Salvestatud {output_path}\")\n",
    "    return grouped\n",
    "\n",
    "\n",
    "#df_verbid_partiklidena = aggregate_section_counts(\n",
    "  #   input_path='tabelid_kontrollimiseks/verbid_partiklidena_sections_uus.csv',\n",
    "  #   output_path='tabelid_kontrollimiseks/sections/verbid_partiklidena_sections.csv',\n",
    "  #   sep=';',\n",
    "# )\n",
    "\n",
    "df_esimese_ja_teise_isik = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/esimese_ja_teise_isik.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/esimese_ja_teise_isik_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_partiklid = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/partiklid.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/partikkel_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_kaskiv = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/kaskiv.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/kaskiv_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_tingiv = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/tingiv.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/tingiv_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_umbisikuline = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/umbisikuline.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/umbisikuline_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_kp = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/kp_markerid.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/kp_markerid_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_umbisikuline = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/umbisikuline.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/umbisikuline_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_omadussonadega = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/intensiivistajad_omdasusonadega.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/intensiivistajad_omadussonadega_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_verbidega = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/intensiivistajad_verbidega.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/intensiivistajad_verbidega_sections.csv',\n",
    "     sep=',',\n",
    " )\n",
    "df_adverbidega = aggregate_section_counts(\n",
    "     input_path='tabelid_kontrollimiseks/intensiivistajad_adverbidega.csv',\n",
    "     output_path='tabelid_kontrollimiseks/sections/intensiivistajad_adverbidega_sections.csv',\n",
    "     sep=',',\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f58b6d3a-ae8c-423d-8002-8017fbf4d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tables_per_particle(\n",
    "    csv_path: str,\n",
    "    column_name: str,\n",
    "    out_dir: str,\n",
    "    threshold: int = None,\n",
    "    delimiter: str = ',',\n",
    "    encoding: str = 'utf-8'\n",
    "):\n",
    "    \n",
    "    df = pd.read_csv(csv_path, sep=delimiter, encoding=encoding)\n",
    "\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for part_value, group in df.groupby(column_name):\n",
    "        #\n",
    "        if threshold is not None and len(group) <= threshold:\n",
    "            continue\n",
    "\n",
    "\n",
    "        safe = re.sub(r'[^\\w\\-]+', '_', str(part_value)).strip('_')\n",
    "        filename = f\"{safe}.csv\"\n",
    "\n",
    "\n",
    "        path = os.path.join(out_dir, filename)\n",
    "        group.to_csv(path, index=False)\n",
    "        print(f\"Salvestatud {len(group)} read → {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f9da304-77fb-4b20-bc7f-43c736ae971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 121 read → .../particles_per_value/aitäh.csv\n",
      "Salvestatud 111 read → .../particles_per_value/jah.csv\n",
      "Salvestatud 59 read → .../particles_per_value/kurat.csv\n",
      "Salvestatud 10957 read → .../particles_per_value/nagu.csv\n",
      "Salvestatud 669 read → .../particles_per_value/no.csv\n",
      "Salvestatud 575 read → .../particles_per_value/noh.csv\n",
      "Salvestatud 58 read → .../particles_per_value/oh.csv\n",
      "Salvestatud 349 read → .../particles_per_value/okei.csv\n",
      "Salvestatud 133 read → .../particles_per_value/vot.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    save_tables_per_particle(\n",
    "        csv_path='tabelid_kontrollimiseks/partiklid.csv',\n",
    "        column_name='partikkel',\n",
    "        out_dir='.../particles_per_value',\n",
    "        threshold=50  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc4b503b-c94d-4c62-a0e4-dbbfcf96e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_section_freq_tables(\n",
    "    input_dir: str,\n",
    "    output_dir: str,\n",
    "    group_cols=('episode_id', 'section_index', 'gender', 'minutes'),\n",
    "    input_sep=',',\n",
    "    output_sep=';'\n",
    "):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pattern = os.path.join(input_dir, '*.csv')\n",
    "    for in_path in glob.glob(pattern):\n",
    "\n",
    "        df = pd.read_csv(in_path, sep=input_sep)\n",
    "        \n",
    "        grouped = (\n",
    "            df\n",
    "            .groupby(list(group_cols), as_index=False)\n",
    "            .size()\n",
    "            .rename(columns={'size': 'absolut_freq'})\n",
    "        )\n",
    "        \n",
    "        if 'minutes' in grouped.columns:\n",
    "            grouped['freq_per_hour'] = grouped['absolut_freq'] / (grouped['minutes'] / 60)\n",
    "        else:\n",
    "\n",
    "            grouped['freq_per_hour'] = grouped['absolut_freq']\n",
    "        \n",
    "        \n",
    "        base = os.path.splitext(os.path.basename(in_path))[0]\n",
    "        out_name = f\"{base}_sections.csv\"\n",
    "        out_path = os.path.join(output_dir, out_name)\n",
    "        grouped.to_csv(out_path, index=False, sep=output_sep)\n",
    "        print(f\"Salvestatud {len(grouped)} read → {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a75a7877-2715-45b7-af9b-51edd9972952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 81 read → .../particles_per_value/sections_partikkel/jah_sections.csv\n",
      "Salvestatud 146 read → .../particles_per_value/sections_partikkel/okei_sections.csv\n",
      "Salvestatud 481 read → .../particles_per_value/sections_partikkel/nagu_sections.csv\n",
      "Salvestatud 71 read → .../particles_per_value/sections_partikkel/vot_sections.csv\n",
      "Salvestatud 77 read → .../particles_per_value/sections_partikkel/aitäh_sections.csv\n",
      "Salvestatud 183 read → .../particles_per_value/sections_partikkel/noh_sections.csv\n",
      "Salvestatud 44 read → .../particles_per_value/sections_partikkel/oh_sections.csv\n",
      "Salvestatud 36 read → .../particles_per_value/sections_partikkel/kurat_sections.csv\n",
      "Salvestatud 211 read → .../particles_per_value/sections_partikkel/no_sections.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    make_section_freq_tables(\n",
    "        input_dir='.../particles_per_value',\n",
    "        output_dir='.../particles_per_value/sections_partikkel'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5cb2af6-a8d1-472e-9033-95a3284db4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 378 read → .../intensiivistajad_adverbidega_per_value/hästi.csv\n",
      "Salvestatud 962 read → .../intensiivistajad_adverbidega_per_value/kui.csv\n",
      "Salvestatud 121 read → .../intensiivistajad_adverbidega_per_value/liiga.csv\n",
      "Salvestatud 161 read → .../intensiivistajad_adverbidega_per_value/natuke.csv\n",
      "Salvestatud 125 read → .../intensiivistajad_adverbidega_per_value/natukene.csv\n",
      "Salvestatud 981 read → .../intensiivistajad_adverbidega_per_value/nii.csv\n",
      "Salvestatud 248 read → .../intensiivistajad_adverbidega_per_value/palju.csv\n",
      "Salvestatud 264 read → .../intensiivistajad_adverbidega_per_value/päris.csv\n",
      "Salvestatud 118 read → .../intensiivistajad_adverbidega_per_value/täiesti.csv\n",
      "Salvestatud 118 read → .../intensiivistajad_adverbidega_per_value/tõesti.csv\n",
      "Salvestatud 911 read → .../intensiivistajad_adverbidega_per_value/väga.csv\n",
      "Salvestatud 131 read → .../intensiivistajad_adverbidega_per_value/üldse.csv\n",
      "Salvestatud 54 read → .../intensiivistajad_adverbidega_per_value/üsna.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    save_tables_per_particle(\n",
    "        csv_path='tabelid_kontrollimiseks/intensiivistajad_adverbidega.csv',\n",
    "        column_name='inetnsiivistaja',\n",
    "        out_dir='.../intensiivistajad_adverbidega_per_value',\n",
    "        threshold=50 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "053ed27d-a8fc-40dc-835e-40808ef48c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 140 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/päris_sections.csv\n",
      "Salvestatud 76 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/liiga_sections.csv\n",
      "Salvestatud 36 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/üsna_sections.csv\n",
      "Salvestatud 91 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/üldse_sections.csv\n",
      "Salvestatud 77 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/täiesti_sections.csv\n",
      "Salvestatud 127 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/palju_sections.csv\n",
      "Salvestatud 272 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/kui_sections.csv\n",
      "Salvestatud 100 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/natuke_sections.csv\n",
      "Salvestatud 141 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/hästi_sections.csv\n",
      "Salvestatud 82 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/natukene_sections.csv\n",
      "Salvestatud 78 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/tõesti_sections.csv\n",
      "Salvestatud 270 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/nii_sections.csv\n",
      "Salvestatud 247 read → .../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega/väga_sections.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    make_section_freq_tables(\n",
    "        input_dir='.../intensiivistajad_adverbidega_per_value',\n",
    "        output_dir='.../intensiivistajad_adverbidega_per_value/sections_intensiivistajad_adverbidega'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf7df14b-142a-47ba-a0a2-31bef348f88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 453 read → .../intensiivistajad_omadussonadega_per_value/hästi.csv\n",
      "Salvestatud 254 read → .../intensiivistajad_omadussonadega_per_value/kui.csv\n",
      "Salvestatud 71 read → .../intensiivistajad_omadussonadega_per_value/liiga.csv\n",
      "Salvestatud 51 read → .../intensiivistajad_omadussonadega_per_value/natuke.csv\n",
      "Salvestatud 681 read → .../intensiivistajad_omadussonadega_per_value/nii.csv\n",
      "Salvestatud 143 read → .../intensiivistajad_omadussonadega_per_value/palju.csv\n",
      "Salvestatud 285 read → .../intensiivistajad_omadussonadega_per_value/päris.csv\n",
      "Salvestatud 57 read → .../intensiivistajad_omadussonadega_per_value/suht.csv\n",
      "Salvestatud 165 read → .../intensiivistajad_omadussonadega_per_value/täiesti.csv\n",
      "Salvestatud 1764 read → .../intensiivistajad_omadussonadega_per_value/väga.csv\n",
      "Salvestatud 67 read → .../intensiivistajad_omadussonadega_per_value/üldse.csv\n",
      "Salvestatud 83 read → .../intensiivistajad_omadussonadega_per_value/üsna.csv\n",
      "Salvestatud 154 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/päris_sections.csv\n",
      "Salvestatud 51 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/liiga_sections.csv\n",
      "Salvestatud 53 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/üsna_sections.csv\n",
      "Salvestatud 47 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/üldse_sections.csv\n",
      "Salvestatud 101 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/täiesti_sections.csv\n",
      "Salvestatud 103 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/palju_sections.csv\n",
      "Salvestatud 152 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/kui_sections.csv\n",
      "Salvestatud 42 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/natuke_sections.csv\n",
      "Salvestatud 137 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/hästi_sections.csv\n",
      "Salvestatud 235 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/nii_sections.csv\n",
      "Salvestatud 34 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/suht_sections.csv\n",
      "Salvestatud 338 read → .../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega/väga_sections.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    save_tables_per_particle(\n",
    "        csv_path='tabelid_kontrollimiseks/intensiivistajad_omdasusonadega.csv',\n",
    "        column_name='inetnsiivistaja',\n",
    "        out_dir='.../intensiivistajad_omadussonadega_per_value',\n",
    "        threshold=50 \n",
    "    )\n",
    "    make_section_freq_tables(\n",
    "        input_dir='.../intensiivistajad_omadussonadega_per_value',\n",
    "        output_dir='.../intensiivistajad_omadussonadega_per_value/sections_intensiivistajad_omadussonadega'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20c05cdb-9dff-48fa-a133-84be708bb64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvestatud 1004 read → .../kp_markerid_per_value/arvan.csv\n",
      "Salvestatud 97 read → .../kp_markerid_per_value/loodan.csv\n",
      "Salvestatud 291 read → .../kp_markerid_per_value/tundub.csv\n",
      "Salvestatud 142 read → .../kp_markerid_per_value/usun.csv\n",
      "Salvestatud 930 read → .../kp_markerid_per_value/ütleme.csv\n",
      "Salvestatud 228 read → .../kp_markerid_per_value/sections_kp_markerid/ütleme_sections.csv\n",
      "Salvestatud 149 read → .../kp_markerid_per_value/sections_kp_markerid/tundub_sections.csv\n",
      "Salvestatud 70 read → .../kp_markerid_per_value/sections_kp_markerid/loodan_sections.csv\n",
      "Salvestatud 255 read → .../kp_markerid_per_value/sections_kp_markerid/arvan_sections.csv\n",
      "Salvestatud 93 read → .../kp_markerid_per_value/sections_kp_markerid/usun_sections.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    save_tables_per_particle(\n",
    "        csv_path='tabelid_kontrollimiseks/kp_markerid.csv',\n",
    "        column_name='verb',\n",
    "        out_dir='.../kp_markerid_per_value',\n",
    "        threshold=50 \n",
    "    )\n",
    "    make_section_freq_tables(\n",
    "        input_dir='.../kp_markerid_per_value',\n",
    "        output_dir='.../kp_markerid_per_value/sections_kp_markerid'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
